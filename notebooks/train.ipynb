{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7f31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T22:36:27.979687Z",
     "iopub.status.busy": "2026-01-25T22:36:27.978644Z",
     "iopub.status.idle": "2026-01-25T22:36:31.220797Z",
     "shell.execute_reply": "2026-01-25T22:36:31.219118Z",
     "shell.execute_reply.started": "2026-01-25T22:36:27.979628Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELLA 1: Setup directories and imports\n",
    "# ============================================================================\n",
    "from __future__ import annotations\n",
    "import sys, os, time, torch\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Literal\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import LinearLR, SequentialLR, CosineAnnealingLR\n",
    "\n",
    "PROJECT_ROOT = str(Path.home() / \"AML\")\n",
    "LOCAL_REPO_NAME = str(Path.home() / \"AML_SemanticCorrespondence\")\n",
    "DATA_DIR = f'{PROJECT_ROOT}/dataset' \n",
    "CHECKPOINT_DIR = f'{PROJECT_ROOT}/checkpoints'\n",
    "LOG_DIR = f'{PROJECT_ROOT}/logs'\n",
    "SPAIR_ROOT = f'{DATA_DIR}/Spair-71k'\n",
    "\n",
    "# Add local repository to path for module imports\n",
    "sys.path.insert(0, LOCAL_REPO_NAME)\n",
    "\n",
    "# Create required directories if they do not exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# Import local modules\n",
    "from models import CorrespondenceMatcher, UnifiedEvaluator, FinetunableBackbone, CorrespondenceLoss\n",
    "from dataset import SPairDataset\n",
    "\n",
    "# Performance optimizations for faster training\n",
    "try:\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "except Exception:\n",
    "    pass\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\" CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"\\n  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"\\n Setup complete!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a959e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T22:36:31.225032Z",
     "iopub.status.busy": "2026-01-25T22:36:31.223328Z",
     "iopub.status.idle": "2026-01-25T22:36:33.444591Z",
     "shell.execute_reply": "2026-01-25T22:36:33.443154Z",
     "shell.execute_reply.started": "2026-01-25T22:36:31.224995Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELLA 2: Install Dependencies\n",
    "# ============================================================================\n",
    "\n",
    "print(\" Installing dependencies...\\n\")\n",
    "!pip install -q -r {LOCAL_REPO_NAME}/requirements.txt\n",
    "print(\"\\n Dependencies installed!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ad408",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T22:36:33.446599Z",
     "iopub.status.busy": "2026-01-25T22:36:33.446250Z",
     "iopub.status.idle": "2026-01-25T22:36:33.459166Z",
     "shell.execute_reply": "2026-01-25T22:36:33.458233Z",
     "shell.execute_reply.started": "2026-01-25T22:36:33.446566Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1769274248554,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "1a1ad408",
    "outputId": "cf8058e7-7d96-4c8f-bfbe-e85a28fcee3f"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELLA 3: Fine-tuning Configuration\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class FinetuneConfig:\n",
    "    # -------------------------\n",
    "    # Model\n",
    "    # -------------------------\n",
    "    backbone_name: str = 'sam_vit_b'        # 'dinov2_vitb14', 'dinov3_vitb16', 'sam_vit_b'\n",
    "    num_layers_to_finetune: int = 2         # last transformer blocks to unfreeze\n",
    "\n",
    "    # -------------------------\n",
    "    # Training\n",
    "    # -------------------------\n",
    "    num_epochs: int = 5                     # total epochs to train\n",
    "    learning_rate: float = 5e-6             # base LR\n",
    "    weight_decay: float = 1e-2              # weight decay\n",
    "    warmup_epochs: int = 1                  # number of warmup epochs in which LR increases linearly to base LR \n",
    "    grad_clip_norm: float = 1.0             # max norm for gradient clipping (set to 0 to disable)\n",
    "    tqdm_update_interval: int = 100         # update progress bar every N batches\n",
    "\n",
    "    # Memory optimizations\n",
    "    use_amp: bool = True                        # automatic mixed precision\n",
    "    gradient_accumulation_steps: int = 8        # number of batches to accumulate before stepping optimizer\n",
    "    use_gradient_checkpointing: bool = False    # save memory by recomputing activations during backward pass\n",
    "\n",
    "    # DataLoader\n",
    "    batch_size: int = 1                         # per-GPU batch size (keep 1)\n",
    "    num_workers: int = 0                        # DataLoader workers (keep 0)\n",
    "    max_train_pairs: Optional[int] = None       # set None for full training set (53340 pairs)\n",
    "    max_val_pairs: int = 1000                   # total of 5384 val pairs\n",
    "\n",
    "    # Loss\n",
    "    loss_type: str = 'contrastive'              # 'cosine' | 'l2' | 'contrastive'\n",
    "    temperature: float = 0.07                   # temp for contrastive loss to sharpen similarities\n",
    "\n",
    "    # -------------------------\n",
    "    # Evaluation modes\n",
    "    # -------------------------\n",
    "    val_mode: Literal[\"slice\", \"full\", \"hybrid\"] = \"hybrid\" # validation mode\n",
    "    val_slice_max_batches: int = 50                         # used in slice/hybrid\n",
    "    val_full_max_batches: Optional[int] = None              # None = full validation\n",
    "    val_full_every: int = 1                                 # run full val every N epochs (hybrid/full)\n",
    "\n",
    "    # -------------------------\n",
    "    # Logging / checkpoints\n",
    "    # -------------------------\n",
    "    use_tensorboard: bool = True                            # TensorBoard logging\n",
    "    tb_logdir: str = \"runs/task2_finetune\"                  # TensorBoard log directory\n",
    "\n",
    "    use_wandb: bool = True                                          # Weights & Biases logging\n",
    "    wandb_entity: str = \"luffy1\"                                    # your W&B username or team name\n",
    "    wandb_project: str = \"AML-project-semantic-correspondence\"      # W&B project name\n",
    "\n",
    "    log_checkpoints_per_epoch: int = 10                     # intra-epoch logs \n",
    "    run_name: str = \"\"                                      # auto if empty\n",
    "\n",
    "    # Training mode\n",
    "    training_mode: Literal[\"fresh\", \"resume\", \"continue\"] = \"fresh\"     # 'fresh' | 'resume' | 'continue'\n",
    "    resume_checkpoint: str = \"\"                                         # used if training_mode == 'resume'\n",
    "\n",
    "config = FinetuneConfig()\n",
    "\n",
    "if not config.run_name:\n",
    "    config.run_name = f\"{config.backbone_name}_L{config.num_layers_to_finetune}_ls512_lr{config.learning_rate}\"\n",
    "\n",
    "\n",
    "IMG_SIZE = 518 if config.backbone_name.startswith(\"dinov2\") else 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891569c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T22:36:49.508259Z",
     "iopub.status.busy": "2026-01-25T22:36:49.507480Z",
     "iopub.status.idle": "2026-01-25T22:36:51.079031Z",
     "shell.execute_reply": "2026-01-25T22:36:51.077832Z",
     "shell.execute_reply.started": "2026-01-25T22:36:49.508217Z"
    },
    "executionInfo": {
     "elapsed": 3212,
     "status": "ok",
     "timestamp": 1769274251770,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "891569c8",
    "outputId": "3b702d7d-7581-483d-897a-1d7dc3869282"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Initialize Weights & Biases logging\n",
    "# ============================================================================\n",
    "import wandb\n",
    "if config.use_wandb:\n",
    "    # Attempt to authenticate with W&B using cached credentials\n",
    "    try:\n",
    "        wandb.login(relogin=False)\n",
    "    except Exception as e:\n",
    "        print(f\"W&B login required. Run 'wandb login' in terminal if needed.\")\n",
    "    \n",
    "    wandb.init(\n",
    "        entity=config.wandb_entity,\n",
    "        project=config.wandb_project,\n",
    "        config={\n",
    "            \"learning_rate\": config.learning_rate,\n",
    "            \"epochs\": config.num_epochs,\n",
    "            \"batch_size\": config.batch_size,\n",
    "            \"num_layers_to_unfreeze\": config.num_layers_to_finetune,\n",
    "            \"model_to_finetune\": (\"sam\" if config.backbone_name.startswith(\"sam\") else (\"dinov2\" if config.backbone_name.startswith(\"dinov2\") else \"dinov3\")),\n",
    "            \"temperature\": config.temperature,\n",
    "            \"loss_type\": config.loss_type,\n",
    "            \"use_amp\": config.use_amp,\n",
    "            \"gradient_accumulation_steps\": config.gradient_accumulation_steps,\n",
    "            \"use_gradient_checkpointing\": config.use_gradient_checkpointing,\n",
    "            \"val_mode\": config.val_mode,\n",
    "        }\n",
    "    )\n",
    "    print(\"W&B run started.\")\n",
    "else:\n",
    "    print(\"W&B disabled by config.use_wandb=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Install SAM dependency if needed\n",
    "# ============================================================================\n",
    "if 'sam' in config.backbone_name:\n",
    "    print(f\" Installing SAM dependency for {config.backbone_name}...\")\n",
    "    !pip install -q git+https://github.com/facebookresearch/segment-anything.git\n",
    "    print(\" SAM dependency installed.\\n\")\n",
    "else:\n",
    "    print(\" SAM not selected â€” skipping.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6bf48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T22:36:58.446438Z",
     "iopub.status.busy": "2026-01-25T22:36:58.446033Z",
     "iopub.status.idle": "2026-01-25T22:36:58.562719Z",
     "shell.execute_reply": "2026-01-25T22:36:58.561733Z",
     "shell.execute_reply.started": "2026-01-25T22:36:58.446374Z"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1769274252402,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "b4e6bf48",
    "outputId": "aaaf7442-229f-4ee1-de32-f3fff85555cd"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: DataLoaders (train/val)\n",
    "# ============================================================================\n",
    "\n",
    "def maybe_subset(ds, max_pairs):                        # subset dataset to max_pairs if not None\n",
    "    if max_pairs is None:\n",
    "        return ds\n",
    "    idx = torch.randperm(len(ds))[:max_pairs].tolist()\n",
    "    return torch.utils.data.Subset(ds, idx)\n",
    "\n",
    "train_dataset_full = SPairDataset(\n",
    "    root=SPAIR_ROOT, split='train', size='large', long_side=IMG_SIZE,\n",
    "    normalize=True, load_segmentation=False\n",
    ")\n",
    "val_dataset_full = SPairDataset(\n",
    "    root=SPAIR_ROOT, split='val', size='large', long_side=IMG_SIZE,\n",
    "    normalize=True, load_segmentation=False\n",
    ")\n",
    "\n",
    "train_ds = maybe_subset(train_dataset_full, config.max_train_pairs)\n",
    "val_ds   = maybe_subset(val_dataset_full, config.max_val_pairs)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers,\n",
    "    pin_memory=torch.cuda.is_available(), drop_last=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers,\n",
    "    pin_memory=torch.cuda.is_available(), drop_last=False\n",
    ")\n",
    "print(f\" Train pairs: {len(train_ds)} | batches: {len(train_loader)}\")\n",
    "print(f\"   Val pairs: {len(val_ds)} | batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6af126",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T22:36:58.564553Z",
     "iopub.status.busy": "2026-01-25T22:36:58.563822Z",
     "iopub.status.idle": "2026-01-25T22:36:58.573630Z",
     "shell.execute_reply": "2026-01-25T22:36:58.572711Z",
     "shell.execute_reply.started": "2026-01-25T22:36:58.564520Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1769274252409,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "fc6af126",
    "outputId": "3df893e8-80c8-483c-b254-72b46a97fb28"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Adapter for FinetunableBackbone compatibility with CorrespondenceMatcher\n",
    "# ============================================================================\n",
    "\n",
    "class FinetunableBackboneAdapter:\n",
    "    \"\"\"Adapter to use FinetunableBackbone with CorrespondenceMatcher interface.\"\"\"\n",
    "    def __init__(self, finetunable_backbone):\n",
    "        self.model = finetunable_backbone\n",
    "        self.device = finetunable_backbone.device\n",
    "        self.config = type('obj', (object,), {'patch_size': finetunable_backbone.stride})()\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()\n",
    "        self.training = False\n",
    "        return self\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        self.training = True\n",
    "        return self\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, img):\n",
    "        \"\"\"Convert batch features (B, H, W, D) -> single image (H, W, D) for matcher.\"\"\"\n",
    "        feat = self.model(img)  # (B, H, W, D)\n",
    "        return feat.squeeze(0),  # (H, W, D) returned as tuple for compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278fc5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T22:36:58.575335Z",
     "iopub.status.busy": "2026-01-25T22:36:58.575041Z",
     "iopub.status.idle": "2026-01-25T22:42:33.984341Z",
     "shell.execute_reply": "2026-01-25T22:42:33.982335Z",
     "shell.execute_reply.started": "2026-01-25T22:36:58.575306Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Training Loop (AMP + Warmup + Grad Clip + TB + Resume + Val modes)\n",
    "# ============================================================================\n",
    "\n",
    "# Evaluator setup\n",
    "evaluator = UnifiedEvaluator(\n",
    "    dataloader=val_loader,\n",
    "    device=device,\n",
    "    thresholds=[0.05, 0.10, 0.15, 0.20]\n",
    ")\n",
    "\n",
    "# Model setup\n",
    "model = FinetunableBackbone(\n",
    "    backbone_name=config.backbone_name,\n",
    "    num_layers_to_finetune=config.num_layers_to_finetune,\n",
    "    device=device,\n",
    "    use_gradient_checkpointing=config.use_gradient_checkpointing,\n",
    ").to(device)\n",
    "\n",
    "# Loss setup\n",
    "criterion = CorrespondenceLoss(loss_type=config.loss_type, temperature=config.temperature).to(device)\n",
    "print(\" Loss:\", config.loss_type)\n",
    "\n",
    "# Optimizer: AdamW on trainable params only\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "if len(trainable_params) == 0:\n",
    "    raise RuntimeError(\"No trainable parameters found. Check num_layers_to_finetune > 0.\")\n",
    "\n",
    "optimizer = optim.AdamW(trainable_params, lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "\n",
    "# Scheduler: warmup -> cosine (step-based)\n",
    "total_updates = max(1, (len(train_loader) * config.num_epochs) // config.gradient_accumulation_steps)\n",
    "warmup_updates = max(1, (len(train_loader) * config.warmup_epochs) // config.gradient_accumulation_steps)\n",
    "\n",
    "warmup = LinearLR(optimizer, start_factor=0.1, total_iters=warmup_updates)\n",
    "cosine = CosineAnnealingLR(optimizer, T_max=max(1, total_updates - warmup_updates))\n",
    "scheduler = SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_updates])\n",
    "\n",
    "# AMP\n",
    "use_amp = bool(config.use_amp and torch.cuda.is_available())\n",
    "scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "print(f\" AMP: {use_amp} | Grad accumulation: {config.gradient_accumulation_steps} | Grad checkpointing: {config.use_gradient_checkpointing}\")\n",
    "\n",
    "# TensorBoard\n",
    "tb_writer = None\n",
    "if config.use_tensorboard:\n",
    "    logdir = Path(config.tb_logdir) / config.run_name\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "    tb_writer = SummaryWriter(log_dir=str(logdir))\n",
    "    print(f\" TensorBoard logdir: {logdir}\")\n",
    "\n",
    "# File Logging setup\n",
    "log_dir_path = Path(LOG_DIR)\n",
    "log_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "log_filename = log_dir_path / f\"train_{config.run_name}_{time.strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "logger = logging.getLogger(f\"finetune_{config.run_name}\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    fh = logging.FileHandler(str(log_filename))\n",
    "    fh.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "    logger.propagate = False\n",
    "logger.info(f\"Starting training: run_name={config.run_name} backbone={config.backbone_name} epochs={config.num_epochs} lr={config.learning_rate}\")\n",
    "\n",
    "# Checkpointing (complete state for resume)\n",
    "best_pck = -1.0\n",
    "start_epoch = 0\n",
    "global_step = 0\n",
    "best_path = Path(CHECKPOINT_DIR) / f\"finetuned_{config.run_name}.pt\"\n",
    "best_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_ckpt(path: Path, epoch: int, best_pck_val: float):\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"global_step\": global_step,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict() if use_amp else None,\n",
    "        \"best_pck@0.10\": best_pck_val,\n",
    "        \"config\": config.__dict__,\n",
    "    }, str(path))\n",
    "\n",
    "if config.training_mode == \"resume\":\n",
    "    ckpt_path = config.resume_checkpoint or str(best_path)\n",
    "    if ckpt_path and os.path.exists(ckpt_path):\n",
    "        print(f\"\\n Resuming from checkpoint: {ckpt_path}\")\n",
    "        logger.info(f\"Resuming from checkpoint: {ckpt_path}\")\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "        model.load_state_dict(ckpt[\"model_state_dict\"], strict=True)\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "        scheduler.load_state_dict(ckpt[\"scheduler_state_dict\"])\n",
    "        if use_amp and ckpt.get(\"scaler_state_dict\") is not None:\n",
    "            scaler.load_state_dict(ckpt[\"scaler_state_dict\"])\n",
    "        start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
    "        global_step = int(ckpt.get(\"global_step\", 0))\n",
    "        best_pck = float(ckpt.get(\"best_pck@0.10\", best_pck))\n",
    "        print(f\"   start_epoch={start_epoch} | global_step={global_step} | best_pck@0.10={best_pck:.2f}\")\n",
    "        logger.info(f\"Resume stats: start_epoch={start_epoch} global_step={global_step} best_pck@0.10={best_pck:.2f}\")\n",
    "    else:\n",
    "        print(f\" resume requested but checkpoint not found: {ckpt_path}\")\n",
    "        print(\"   Continuing from current weights in memory.\")\n",
    "        logger.warning(f\"Resume requested but checkpoint not found: {ckpt_path}. Continuing.\")\n",
    "elif config.training_mode == \"fresh\":\n",
    "    print(\"\\n Training mode: fresh (starting from pretrained weights loaded by backbone extractor)\")\n",
    "    logger.info(\"Training mode: fresh\")\n",
    "else:\n",
    "    print(\"\\n Training mode: continue (keeping current weights in memory)\")\n",
    "    logger.info(\"Training mode: continue\")\n",
    "\n",
    "# Intra-epoch log checkpoints\n",
    "def get_log_steps(n_batches: int, k: int):\n",
    "    if k <= 0:\n",
    "        return set()\n",
    "    if n_batches <= 1:\n",
    "        return {0}\n",
    "    steps = set(int(round(x)) for x in np.linspace(0, n_batches - 1, k))\n",
    "    return steps\n",
    "\n",
    "log_steps = get_log_steps(len(train_loader), config.log_checkpoints_per_epoch)\n",
    "\n",
    "\n",
    "# Validation function using UnifiedEvaluator\n",
    "@torch.no_grad()\n",
    "def run_validation_unified(model_wrapper, num_samples=None):\n",
    "    \"\"\"Run validation using UnifiedEvaluator (consistent with eval.ipynb)\"\"\"\n",
    "    matcher = CorrespondenceMatcher(model_wrapper, use_soft_argmax=False)\n",
    "    \n",
    "    results = evaluator.evaluate(\n",
    "        matcher=matcher,\n",
    "        backbone_name=f\"finetuned_{config.backbone_name}\",\n",
    "        num_samples=num_samples,\n",
    "        show_progress=False\n",
    "    )\n",
    "    \n",
    "    # Extract PCK@0.10 and loss\n",
    "    pck_010 = results['overall_keypoint']['PCK@0.10']['mean'] * 100.0\n",
    "    \n",
    "    return pck_010, results\n",
    "\n",
    "# One epoch training\n",
    "def train_one_epoch(epoch: int):\n",
    "    global global_step\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    pbar = tqdm(total=len(train_loader), desc=f\"Train {epoch+1}/{config.num_epochs}\", leave=False)\n",
    "\n",
    "    accumulated = 0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        src = batch[\"src_img\"].to(device, non_blocking=True)\n",
    "        tgt = batch[\"tgt_img\"].to(device, non_blocking=True)\n",
    "        src_kps = batch[\"src_kps\"].to(device, non_blocking=True)\n",
    "        tgt_kps = batch[\"tgt_kps\"].to(device, non_blocking=True)\n",
    "        vm = batch[\"valid_mask\"].to(device, non_blocking=True)\n",
    "\n",
    "        with autocast(enabled=use_amp):\n",
    "            src_feat = model(src)\n",
    "            tgt_feat = model(tgt)\n",
    "            loss = criterion(src_feat, tgt_feat, src_kps, tgt_kps, vm, patch_size=model.stride)\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        accumulated += 1\n",
    "\n",
    "        do_update = (accumulated == config.gradient_accumulation_steps) or (step + 1 == len(train_loader))\n",
    "\n",
    "        if do_update:\n",
    "            if config.grad_clip_norm is not None and config.grad_clip_norm > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip_norm)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            scheduler.step()\n",
    "            accumulated = 0\n",
    "            global_step += 1\n",
    "\n",
    "        epoch_losses.append(float(loss.item() * config.gradient_accumulation_steps))\n",
    "\n",
    "        should_refresh = ((step + 1) % config.tqdm_update_interval == 0) or ((step + 1) == len(train_loader))\n",
    "        if should_refresh:\n",
    "            pbar.update((step + 1) - pbar.n)\n",
    "            try:\n",
    "                lr_now = scheduler.get_last_lr()[0]\n",
    "            except Exception:\n",
    "                lr_now = optimizer.param_groups[0].get('lr', config.learning_rate)\n",
    "            pbar.set_postfix({\"loss\": f\"{np.mean(epoch_losses):.4f}\", \"lr\": f\"{lr_now:.2e}\"})\n",
    "            logger.info(f\"epoch={epoch+1} step={step+1}/{len(train_loader)} loss={np.mean(epoch_losses):.4f} lr={lr_now:.2e} global_step={global_step}\")\n",
    "\n",
    "\n",
    "        if config.use_wandb and (step in log_steps) and (step > 0):\n",
    "            avg_train_loss = float(np.mean(epoch_losses)) if len(epoch_losses) else 0.0\n",
    "            \n",
    "            t_eval0 = time.time()\n",
    "            model_wrapper = FinetunableBackboneAdapter(model)\n",
    "            score, _ = run_validation_unified(model_wrapper, num_samples=10) \n",
    "            t_eval = time.time() - t_eval0\n",
    "\n",
    "            pbar.write(\n",
    "                f\"[Intra-epoch eval] epoch={epoch+1} step={step+1}/{len(train_loader)} | \"\n",
    "                f\"PCK@0.10={score:.2f} | {t_eval:.1f}s\"\n",
    "            )\n",
    "            \n",
    "            wandb.log({\n",
    "                \"training loss\": avg_train_loss,\n",
    "                \"validation pck\": score,\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"batch\": step + 1,\n",
    "                \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "            })\n",
    "            \n",
    "            model.train()  # ensure model is back in train mode after eval\n",
    "\n",
    "    pbar.update(len(train_loader) - pbar.n)\n",
    "    pbar.close()\n",
    "    return float(np.mean(epoch_losses)) if len(epoch_losses) else 0.0\n",
    "\n",
    "print(\"\\n Starting fine-tuning...\\n\")\n",
    "logger.info(\"Starting fine-tuning loop\")\n",
    "\n",
    "for epoch in range(start_epoch, config.num_epochs):\n",
    "    t0 = time.time()\n",
    "    train_loss = train_one_epoch(epoch)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    model_wrapper = FinetunableBackboneAdapter(model)\n",
    "    \n",
    "    if config.val_mode == \"slice\":\n",
    "        num_samples = config.val_slice_max_batches\n",
    "    elif config.val_mode == \"full\":\n",
    "        num_samples = config.val_full_max_batches if (epoch + 1) % config.val_full_every == 0 else None\n",
    "    else:  # hybrid\n",
    "        num_samples = config.val_slice_max_batches if (epoch + 1) % config.val_full_every != 0 else config.val_full_max_batches\n",
    "\n",
    "    score, val_results = run_validation_unified(model_wrapper, num_samples=num_samples)\n",
    "\n",
    "    print(f\"\\n Epoch {epoch+1}/{config.num_epochs} | train_loss={train_loss:.4f} | PCK@0.10={score:.2f} | {dt:.1f}s\")\n",
    "    logger.info(f\"Epoch summary: epoch={epoch+1} train_loss={train_loss:.4f} PCK@0.10={score:.2f} time={dt:.1f}s\")\n",
    "\n",
    "    # TensorBoard\n",
    "    if tb_writer is not None:\n",
    "        tb_writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "        tb_writer.add_scalar(\"val/pck@0.10\", score, epoch)\n",
    "\n",
    "    # wandb end-of-epoch logging\n",
    "    if config.use_wandb:\n",
    "        wandb.log({\n",
    "            \"training loss\": train_loss,\n",
    "            \"validation pck\": score,\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "        })\n",
    "\n",
    "    # Save best checkpoint\n",
    "    if score > best_pck:\n",
    "        best_pck = score\n",
    "        save_ckpt(best_path, epoch, best_pck)\n",
    "        print(f\"Saved best checkpoint: {best_path} (PCK@0.10={best_pck:.2f})\")\n",
    "        logger.info(f\"Saved best checkpoint: path={best_path} PCK@0.10={best_pck:.2f}\")\n",
    "\n",
    "print(\"\\nFine-tuning complete.\")\n",
    "print(f\"Best PCK@0.10: {best_pck:.2f}\")\n",
    "logger.info(f\"Fine-tuning complete. Best PCK@0.10={best_pck:.2f}\")\n",
    "\n",
    "if tb_writer is not None:\n",
    "    tb_writer.close()\n",
    "\n",
    "# Finish W&B run\n",
    "if config.use_wandb:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26639085-73b6-49e9-906a-4c5d7ef9e489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m138",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m138"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
