{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj-JAohKd36B",
        "outputId": "dac3c4bc-89ec-44ab-bfb6-e18e0d39d5fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " AML Semantic Correspondence - Training-Free Baseline\n",
            "\n",
            "Mounted at /content/drive\n",
            " Google Drive mounted\n",
            "\n",
            "\n",
            " Cloning repository https://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@github.com/SamueleCarrea/AML_SemanticCorrespondence into AML_SemanticCorrespondence...\n",
            "Cloning into 'AML_SemanticCorrespondence'...\n",
            "remote: Enumerating objects: 286, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 286 (delta 39), reused 56 (delta 19), pack-reused 203 (from 1)\u001b[K\n",
            "Receiving objects: 100% (286/286), 134.84 KiB | 8.99 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            " Repository cloned\n",
            "\n",
            "  GPU: No GPU\n",
            "\n",
            " Setup complete!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELLA 1: Setup Progetto (usando struttura esistente)\n",
        "# ============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\" AML Semantic Correspondence - Training-Free Baseline\\n\")\n",
        "\n",
        "# 1. Mount Google Drive (se non già montato)\n",
        "if not Path('/content/drive').exists():\n",
        "    drive.mount('/content/drive')\n",
        "    print(\" Google Drive mounted\\n\")\n",
        "else:\n",
        "    print(\" Google Drive already mounted\\n\")\n",
        "\n",
        "# 2. Usa la tua struttura esistente\n",
        "PROJECT_ROOT = '/content/drive/MyDrive/AML'\n",
        "LOCAL_REPO_NAME = 'AML_SemanticCorrespondence'\n",
        "DATA_DIR = f'{PROJECT_ROOT}/dataset' # Reverted to 'dataset' as per original context\n",
        "CHECKPOINT_DIR = f'{PROJECT_ROOT}/checkpoints'\n",
        "RESULTS_DIR = f'{PROJECT_ROOT}/results'\n",
        "\n",
        "# Ensure these directories exist (they will be created inside MyDrive/AML)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# 3. Clone/Copy repository files\n",
        "GITHUB_REPO_URL = 'https://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@github.com/SamueleCarrea/AML_SemanticCorrespondence'\n",
        "\n",
        "if not Path(LOCAL_REPO_NAME).exists():\n",
        "    print(f\"\\n Cloning repository {GITHUB_REPO_URL} into {LOCAL_REPO_NAME}...\")\n",
        "    !git clone {GITHUB_REPO_URL} {LOCAL_REPO_NAME}\n",
        "    print(\" Repository cloned\")\n",
        "else:\n",
        "    print(f\"\\n Repository {LOCAL_REPO_NAME} already exists.\")\n",
        "    # Check if it's a git repo before trying to pull\n",
        "    if Path(LOCAL_REPO_NAME, '.git').exists():\n",
        "        print(\" Pulling latest changes...\")\n",
        "        %cd {LOCAL_REPO_NAME}\n",
        "        !git pull\n",
        "        %cd ..\n",
        "        print(\" Repository updated\")\n",
        "    else:\n",
        "        print(\" Directory exists but is not a Git repository. Skipping pull.\")\n",
        "\n",
        "# Aggiungi al path la directory locale del repository\n",
        "sys.path.insert(0, LOCAL_REPO_NAME)\n",
        "\n",
        "# 4. Verifica GPU\n",
        "import torch\n",
        "print(f\"\\n  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "print(\"\\n Setup complete!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELLA 1: Setup Progetto Jupyter\n",
        "# ============================================================================\n",
        "\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "print(\" AML Semantic Correspondence - Training-Free Baseline\\n\")\n",
        "PROJECT_ROOT = str(Path.home() / \"AML\")\n",
        "LOCAL_REPO_NAME = str(Path.home() / \"AML_SemanticCorrespondence\")\n",
        "DATA_DIR = f'{PROJECT_ROOT}/dataset' \n",
        "CHECKPOINT_DIR = f'{PROJECT_ROOT}/checkpoints'\n",
        "RESULTS_DIR = f'{PROJECT_ROOT}/results'\n",
        "\n",
        "# Ensure these directories exist (they will be created inside MyDrive/AML)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Aggiungi al path la directory locale del repository\n",
        "sys.path.insert(0, LOCAL_REPO_NAME)\n",
        "\n",
        "# 4. Verifica GPU\n",
        "print(f\"\\n  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "print(\"\\n Setup complete!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELLA 1b: Scelta backbones, finetuning, dataset e metodo di prediction\n",
        "# ============================================================================\n",
        "backbone_choice = 'dinov2'  # 'dinov2', 'dinov3', 'sam'\n",
        "finetune_choice = False     # True, False\n",
        "soft_argmax_choice = True  # True, False\n",
        "dataset_choice = 'spair'   # 'spair', 'pfwillow'\n",
        "# ============================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szECarDEfY7S",
        "outputId": "8a895365-866e-44c8-d0c4-6c5be2da5be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Installing dependencies...\n",
            "\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.4/86.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            " PyTorch 2.9.0+cpu\n",
            " CUDA available: False\n",
            " Dependencies installed!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELLA 2: Install Dependencies\n",
        "# ============================================================================\n",
        "\n",
        "print(\" Installing dependencies...\\n\")\n",
        "\n",
        "# Installa da requirements.txt clonato\n",
        "!pip install -q -r {LOCAL_REPO_NAME}/requirements.txt\n",
        "\n",
        "print(\" Dependencies installed!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyWnOAFugfAp",
        "outputId": "bd58abce-4c6b-4747-f86d-2b9394439ce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded 12234 pairs from test split (large)\n",
            " Loaded 12234 pairs from test split (large)\n",
            " Sample pair: aeroplane:2008_002719-2008_004100\n",
            " Image shapes: src=torch.Size([3, 345, 518]), tgt=torch.Size([3, 344, 518])\n",
            " Keypoints: 3 correspondences\n",
            "  Category: aeroplane\n",
            "\n",
            " Available keys in sample:\n",
            "   - src_img: torch.Size([3, 345, 518]) (torch.float32)\n",
            "   - tgt_img: torch.Size([3, 344, 518]) (torch.float32)\n",
            "   - src_kps: torch.Size([3, 2]) (torch.float32)\n",
            "   - tgt_kps: torch.Size([3, 2]) (torch.float32)\n",
            "   - valid_mask: torch.Size([3]) (torch.bool)\n",
            "   - category: aeroplane\n",
            "   - pair_id: aeroplane:2008_002719-2008_004100\n",
            "   - src_scale: torch.Size([]) (torch.float32)\n",
            "   - tgt_scale: torch.Size([]) (torch.float32)\n",
            "   - src_orig_size: torch.Size([2]) (torch.int64)\n",
            "   - tgt_orig_size: torch.Size([2]) (torch.int64)\n",
            "   - src_bbox: torch.Size([4]) (torch.float32)\n",
            "   - tgt_bbox: torch.Size([4]) (torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELLA 3: Load  Dataset\n",
        "# ============================================================================\n",
        "\n",
        "from dataset import SPairDataset, PFWillowDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "DATASET_ROOT = f'{DATA_DIR}/Spair-71k' if dataset_choice == 'spair' else f'{DATA_DIR}/PF-Willow'\n",
        "\n",
        "if not Path(DATASET_ROOT).exists():\n",
        "    raise FileNotFoundError(f\"Dataset not found: {DATASET_ROOT}\")\n",
        "\n",
        "if dataset_choice == 'spair':\n",
        "    # Load dataset\n",
        "    test_dataset = SPairDataset(\n",
        "        root=DATASET_ROOT,\n",
        "        split='test',\n",
        "        size='large',\n",
        "        long_side=518,\n",
        "        normalize=True,\n",
        "        load_segmentation=False\n",
        "    )\n",
        "\n",
        "    # DataLoader\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=torch.cuda.is_available()\n",
        "    )\n",
        "else:   #Preparato per poterci aggiungere PF-Willow\n",
        "    # Load dataset\n",
        "    test_dataset = PFWillowDataset(\n",
        "        root=DATASET_ROOT,\n",
        "        long_side=518,\n",
        "        normalize=True\n",
        "    )\n",
        "\n",
        "    # Create DataLoader (batch_size=1 importante!)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        collate_fn=PFWillowDataset.collate_fn\n",
        "    )\n",
        "# ============================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQfunoH8gjHf",
        "outputId": "37eba21b-ab39-4325-d937-6c3c9c7e2d64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Available Backbones:\n",
            "============================================================\n",
            "   dinov2_vitb14        → DINOv2-ViT-B/14\n",
            "   dinov3_vitb16        → DINOv3-ViT-B/16\n",
            "   sam_vit_b            → SAM-ViT-B\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELLA 4: Display Available Backbones\n",
        "# ============================================================================\n",
        "\n",
        "from models import BACKBONE_REGISTRY\n",
        "\n",
        "print(\"✓ Available Backbones:\")\n",
        "print(\"=\"*60)\n",
        "for name, config in BACKBONE_REGISTRY.items():\n",
        "    print(f\"  • {name:15s} → {config.name} (patch={config.patch_size})\")\n",
        "print(\"=\"*60)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlF_Vgmngt2q",
        "outputId": "cf0370da-8486-4ba0-e2a3-0d7a4d058b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Unified matcher ready!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELLA 5: Imports for Evaluation\n",
        "# ============================================================================\n",
        "\n",
        "from models import UnifiedBackbone, CorrespondenceMatcher, UnifiedEvaluator\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"✓ All modules imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f9KkzVFg6I1",
        "outputId": "1208e017-ea45-4c06-cda8-9357e07fc26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Testing PCK metrics...\n",
            "\n",
            " PCK Results (overall):\n",
            "   PCK@0.05: 1.0000 (100.00%)\n",
            "   PCK@0.10: 1.0000 (100.00%)\n",
            "   PCK@0.15: 1.0000 (100.00%)\n",
            "   PCK@0.20: 1.0000 (100.00%)\n",
            "\n",
            " Metrics implementation working!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELLA 6: Quick Test - Verify PCK Metrics\n",
        "# ============================================================================\n",
        "\n",
        "from utils import compute_pck\n",
        "\n",
        "# Test\n",
        "pred = torch.tensor([[100.0, 150.0], [200.0, 250.0]])\n",
        "gt = torch.tensor([[105.0, 155.0], [195.0, 245.0]])\n",
        "img_size = (480, 640)\n",
        "\n",
        "pck_results = compute_pck(pred, gt, img_size)\n",
        "\n",
        "print(\"✓ PCK metrics working:\")\n",
        "for metric, value in pck_results.items():\n",
        "    print(f\"  • {metric}: {value*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z74I72F_g-MG",
        "outputId": "8c3ca5cd-110c-4deb-824d-14209b0cf509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n",
            " Unified evaluator ready!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELLA 7: Main Evaluation - Run Based on Configuration\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"EVALUATION CONFIGURATION (from Cell 1b)\")\n",
        "print('='*70)\n",
        "print(f\"  Backbone: {backbone_choice}\")\n",
        "print(f\"  Finetune: {finetune_choice}\")\n",
        "print(f\"  Soft Argmax: {soft_argmax_choice}\")\n",
        "print(f\"  Dataset: {dataset_choice}\")\n",
        "print('='*70)\n",
        "\n",
        "# Initialize backbone\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"\\nDevice: {device}\\n\")\n",
        "\n",
        "backbone = UnifiedBackbone(\n",
        "    backbone_choice=backbone_choice,\n",
        "    finetune_choice=finetune_choice,\n",
        "    checkpoint_dir=CHECKPOINT_DIR,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Initialize matcher\n",
        "matcher = CorrespondenceMatcher(\n",
        "    backbone=backbone,\n",
        "    use_soft_argmax=soft_argmax_choice\n",
        ")\n",
        "\n",
        "# Initialize evaluator\n",
        "evaluator = UnifiedEvaluator(\n",
        "    dataloader=test_loader,\n",
        "    device=device,\n",
        "    thresholds=[0.05, 0.10, 0.15, 0.20]\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Evaluation setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "JWdsxbkahCHv",
        "outputId": "ae2d0f2c-ae11-46e9-fd5f-dc7de54c5cbc"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELLA 8A: Evaluate Backbone\n",
        "# ============================================================================\n",
        "\n",
        "# Configuration for evaluation run\n",
        "NUM_SAMPLES = None  # None = evaluate all, or set to e.g. 100 for testing\n",
        "\n",
        "print(f\"Evaluating {backbone_choice} on SPair-71k test set\")\n",
        "print(f\"Samples: {NUM_SAMPLES if NUM_SAMPLES else 'ALL'}\\n\")\n",
        "\n",
        "# Run evaluation\n",
        "results = evaluator.evaluate(\n",
        "    matcher=matcher,\n",
        "    backbone_name=backbone.config.name,\n",
        "    num_samples=NUM_SAMPLES,\n",
        "    show_progress=True\n",
        ")\n",
        "\n",
        "# Save results\n",
        "output_filename = f'{backbone_choice}_results.json'\n",
        "output_file = Path(RESULTS_DIR) / output_filename\n",
        "\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\n✓ Results saved: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lumBUtEjrtRu"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CELLA 8B: Load & Compare Results (Optional)\n",
        "# ============================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Loading evaluation results...\\n\")\n",
        "\n",
        "# Load results from file\n",
        "if output_file.exists():\n",
        "    with open(output_file, 'r') as f:\n",
        "        loaded_results = json.load(f)\n",
        "    \n",
        "    print(f\"✓ Loaded: {output_file.name}\\n\")\n",
        "    \n",
        "    # Display summary\n",
        "    print(\"=\"*70)\n",
        "    print(f\"SUMMARY: {loaded_results['name']}\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Samples evaluated: {loaded_results['num_pairs']}\")\n",
        "    print(f\"Avg inference time: {loaded_results['inference_time_ms']:.2f} ms/pair\\n\")\n",
        "    \n",
        "    print(\"PCK Metrics:\")\n",
        "    for metric, vals in loaded_results['overall'].items():\n",
        "        print(f\"  {metric}: {vals['mean']*100:.2f}% ± {vals['std']*100:.2f}%\")\n",
        "    print(\"=\"*70)\n",
        "else:\n",
        "    print(f\"Results file not found: {output_file}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
