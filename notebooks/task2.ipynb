{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ede936-e6f8-4f30-8d74-a2bf9b2ebd66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T11:30:38.166889Z",
     "iopub.status.busy": "2026-01-25T11:30:38.165744Z",
     "iopub.status.idle": "2026-01-25T11:30:39.450520Z",
     "shell.execute_reply": "2026-01-25T11:30:39.449642Z",
     "shell.execute_reply.started": "2026-01-25T11:30:38.166848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AML Semantic Correspondence\n",
      "\n",
      "\n",
      "  GPU: Tesla V100-SXM2-16GB\n",
      "   VRAM: 16.9 GB\n",
      "\n",
      " Setup complete!\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9b9abc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T11:30:39.453162Z",
     "iopub.status.busy": "2026-01-25T11:30:39.452380Z",
     "iopub.status.idle": "2026-01-25T11:30:45.411986Z",
     "shell.execute_reply": "2026-01-25T11:30:45.410296Z",
     "shell.execute_reply.started": "2026-01-25T11:30:39.453123Z"
    },
    "executionInfo": {
     "elapsed": 15629,
     "status": "ok",
     "timestamp": 1769274248501,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "df9b9abc",
    "outputId": "cfa00f88-570f-44b7-adfa-1ac91948233b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Installing dependencies...\n",
      "\n",
      "\n",
      " PyTorch 2.10.0+cu128\n",
      " CUDA available: True\n",
      "\n",
      " Dependencies installed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELLA 2: Install Dependencies\n",
    "# ============================================================================\n",
    "\n",
    "print(\" Installing dependencies...\\n\")\n",
    "\n",
    "!pip install -q -r {LOCAL_REPO_NAME}/requirements.txt\n",
    "!pip install -q tensorboard\n",
    "!pip install -q wandb\n",
    "\n",
    "# Performance settings (safe defaults for Colab)\n",
    "try:\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "except Exception:\n",
    "    pass\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "print(f\"\\n PyTorch {torch.__version__}\")\n",
    "print(f\" CUDA available: {torch.cuda.is_available()}\")\n",
    "print(\"\\n Dependencies installed!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ad408",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T11:30:45.415479Z",
     "iopub.status.busy": "2026-01-25T11:30:45.415121Z",
     "iopub.status.idle": "2026-01-25T11:30:45.431245Z",
     "shell.execute_reply": "2026-01-25T11:30:45.430068Z",
     "shell.execute_reply.started": "2026-01-25T11:30:45.415434Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1769274248554,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "1a1ad408",
    "outputId": "cf8058e7-7d96-4c8f-bfbe-e85a28fcee3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fine-tuning config:\n",
      "\n",
      "  - backbone_name: sam_vit_b\n",
      "  - num_layers_to_finetune: 2\n",
      "  - num_epochs: 3\n",
      "  - learning_rate: 5e-06\n",
      "  - weight_decay: 0.01\n",
      "  - warmup_epochs: 1\n",
      "  - grad_clip_norm: 1.0\n",
      "  - use_amp: True\n",
      "  - gradient_accumulation_steps: 4\n",
      "  - use_gradient_checkpointing: False\n",
      "  - batch_size: 1\n",
      "  - num_workers: 0\n",
      "  - max_train_pairs: 20000\n",
      "  - max_val_pairs: 500\n",
      "  - max_test_pairs: None\n",
      "  - loss_type: contrastive\n",
      "  - temperature: 0.07\n",
      "  - val_mode: hybrid\n",
      "  - val_slice_max_batches: 25\n",
      "  - val_full_max_batches: None\n",
      "  - val_full_every: 1\n",
      "  - do_test_eval: True\n",
      "  - use_tensorboard: True\n",
      "  - tb_logdir: runs/task2_finetune\n",
      "  - use_wandb: False\n",
      "  - wandb_entity: luffy1\n",
      "  - wandb_project: AML-project-semantic-correspondence\n",
      "  - log_checkpoints_per_epoch: 4\n",
      "  - run_name: sam_vit_b_L2_ls512_lr5e-06\n",
      "  - training_mode: fresh\n",
      "  - resume_checkpoint: \n",
      "\n",
      " Image resize target (square padding): 512x512\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELLA 2: Fine-tuning Configuration\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class FinetuneConfig:\n",
    "    # -------------------------\n",
    "    # Model\n",
    "    # -------------------------\n",
    "    backbone_name: str = 'sam_vit_b'   # 'dinov2_vitb14', 'dinov3_vitb16', 'sam_vit_b/l/h'\n",
    "    num_layers_to_finetune: int = 2       # last transformer blocks to unfreeze\n",
    "\n",
    "    # -------------------------\n",
    "    # Training\n",
    "    # -------------------------\n",
    "    num_epochs: int = 3\n",
    "    learning_rate: float = 5e-6\n",
    "    weight_decay: float = 1e-2\n",
    "    warmup_epochs: int = 1\n",
    "    grad_clip_norm: float = 1.0\n",
    "\n",
    "    # Memory optimizations\n",
    "    use_amp: bool = True\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    use_gradient_checkpointing: bool = False   # implemented with best-effort (see model wrapper)\n",
    "\n",
    "    # DataLoader\n",
    "    batch_size: int = 1\n",
    "    num_workers: int = 0                       # keep 0 if dataset is on Drive\n",
    "    max_train_pairs: Optional[int] = None     # set None for full train\n",
    "    max_val_pairs: int = 1000                   # keep validation fast\n",
    "\n",
    "    # Loss\n",
    "    loss_type: str = 'contrastive'             # 'cosine' | 'l2' | 'contrastive'\n",
    "    temperature: float = 0.07\n",
    "\n",
    "    # -------------------------\n",
    "    # Evaluation modes\n",
    "    # -------------------------\n",
    "    val_mode: Literal[\"slice\", \"full\", \"hybrid\"] = \"hybrid\"\n",
    "    val_slice_max_batches: int = 25            # used in slice/hybrid\n",
    "    val_full_max_batches: Optional[int] = None # None = full validation\n",
    "    val_full_every: int = 1                    # run full val every N epochs (hybrid/full)\n",
    "\n",
    "    # -------------------------\n",
    "    # Logging / checkpoints\n",
    "    # -------------------------\n",
    "    use_tensorboard: bool = True\n",
    "    tb_logdir: str = \"runs/task2_finetune\"\n",
    "\n",
    "    use_wandb: bool = True\n",
    "    wandb_entity: str = \"luffy1\"\n",
    "    wandb_project: str = \"AML-project-semantic-correspondence\"\n",
    "\n",
    "    log_checkpoints_per_epoch: int = 4         # intra-epoch logs \n",
    "    run_name: str = \"\"                         # auto if empty\n",
    "\n",
    "    # Training mode\n",
    "    training_mode: Literal[\"fresh\", \"resume\", \"continue\"] = \"fresh\"\n",
    "    resume_checkpoint: str = \"\"                # used if training_mode == 'resume'\n",
    "\n",
    "config = FinetuneConfig()\n",
    "\n",
    "if not config.run_name:\n",
    "    config.run_name = f\"{config.backbone_name}_L{config.num_layers_to_finetune}_ls512_lr{config.learning_rate}\"\n",
    "\n",
    "# Align image size with main.ipynb\n",
    "def get_img_size(backbone_name: str) -> int:\n",
    "    if backbone_name.startswith(\"dinov2\"):\n",
    "        return 518\n",
    "    return 512\n",
    "\n",
    "IMG_SIZE = get_img_size(config.backbone_name if not config.backbone_name.startswith(\"sam\") else \"sam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891569c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T09:32:27.829545Z",
     "iopub.status.busy": "2026-01-25T09:32:27.829235Z",
     "iopub.status.idle": "2026-01-25T09:32:29.023348Z",
     "shell.execute_reply": "2026-01-25T09:32:29.022167Z",
     "shell.execute_reply.started": "2026-01-25T09:32:27.829519Z"
    },
    "executionInfo": {
     "elapsed": 3212,
     "status": "ok",
     "timestamp": 1769274251770,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "891569c8",
    "outputId": "3b702d7d-7581-483d-897a-1d7dc3869282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb disabled by config.use_wandb=False\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELLA 3: wandb init \n",
    "# ============================================================================\n",
    "\n",
    "if config.use_wandb:\n",
    "    wandb.init(\n",
    "        entity=config.wandb_entity,\n",
    "        project=config.wandb_project,\n",
    "        config={\n",
    "            \"learning_rate\": config.learning_rate,\n",
    "            \"epochs\": config.num_epochs,\n",
    "            \"batch_size\": config.batch_size,\n",
    "            \"num_layers_to_unfreeze\": config.num_layers_to_finetune,\n",
    "            \"model_to_finetune\": (\"sam\" if config.backbone_name.startswith(\"sam\") else (\"dinov2\" if config.backbone_name.startswith(\"dinov2\") else \"dinov3\")),\n",
    "            \"temperature\": config.temperature,\n",
    "            \"loss_type\": config.loss_type,\n",
    "            \"use_amp\": config.use_amp,\n",
    "            \"gradient_accumulation_steps\": config.gradient_accumulation_steps,\n",
    "            \"use_gradient_checkpointing\": config.use_gradient_checkpointing,\n",
    "            \"val_mode\": config.val_mode,\n",
    "        }\n",
    "    )\n",
    "    print(\"wandb run started.\")\n",
    "else:\n",
    "    print(\"wandb disabled by config.use_wandb=False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead24529",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T09:32:29.025609Z",
     "iopub.status.busy": "2026-01-25T09:32:29.024903Z",
     "iopub.status.idle": "2026-01-25T09:32:36.012882Z",
     "shell.execute_reply": "2026-01-25T09:32:36.011562Z",
     "shell.execute_reply.started": "2026-01-25T09:32:29.025555Z"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1769274251807,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "ead24529",
    "outputId": "c10591a8-eab8-4ddc-d625-6d4efbfd48f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Installing SAM dependency for sam_vit_b...\n",
      " SAM dependency installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CELLA 4: Install SAM dependency\n",
    "# ============================================================================\n",
    "if 'sam' in config.backbone_name:\n",
    "    print(f\" Installing SAM dependency for {config.backbone_name}...\")\n",
    "    !pip install -q git+https://github.com/facebookresearch/segment-anything.git\n",
    "    print(\" SAM dependency installed.\\n\")\n",
    "else:\n",
    "    print(\" SAM not selected ‚Äî skipping.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zyFPdPNg8--E",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T09:32:36.018205Z",
     "iopub.status.busy": "2026-01-25T09:32:36.017846Z",
     "iopub.status.idle": "2026-01-25T09:32:36.034196Z",
     "shell.execute_reply": "2026-01-25T09:32:36.033172Z",
     "shell.execute_reply.started": "2026-01-25T09:32:36.018172Z"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1769274252001,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "zyFPdPNg8--E"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELLA 5: Loss functions for semantic correspondence fine-tuning\n",
    "# ============================================================================\n",
    "\n",
    "class CorrespondenceLoss(nn.Module):\n",
    "    \"\"\"Loss function for semantic correspondence fine-tuning.\n",
    "\n",
    "    Supports multiple loss types:\n",
    "    - 'cosine': Maximize cosine similarity between corresponding features\n",
    "    - 'l2': Minimize L2 distance between corresponding features\n",
    "    - 'contrastive': InfoNCE-style contrastive loss with negative sampling\n",
    "\n",
    "    Args:\n",
    "        loss_type: Type of loss ('cosine', 'l2', 'contrastive')\n",
    "        negative_margin: Margin for negative samples\n",
    "        temperature: Temperature for contrastive loss\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        loss_type: str = 'cosine',\n",
    "        negative_margin: float = 0.2,\n",
    "        temperature: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss_type = loss_type\n",
    "        self.negative_margin = negative_margin\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src_features: torch.Tensor,\n",
    "        tgt_features: torch.Tensor,\n",
    "        src_kps: torch.Tensor,\n",
    "        tgt_kps: torch.Tensor,\n",
    "        valid_mask: torch.Tensor,\n",
    "        patch_size: int\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Compute correspondence loss.\n",
    "\n",
    "        Args:\n",
    "            src_features: (B, H_s, W_s, D)\n",
    "            tgt_features: (B, H_t, W_t, D)\n",
    "            src_kps: (B, N, 2) source keypoints in pixel coords\n",
    "            tgt_kps: (B, N, 2) target keypoints in pixel coords\n",
    "            valid_mask: (B, N) valid keypoint mask\n",
    "            patch_size: Patch size of the backbone\n",
    "\n",
    "        Returns:\n",
    "            loss: Scalar tensor\n",
    "        \"\"\"\n",
    "        B = src_features.shape[0]\n",
    "        total_loss = 0.0\n",
    "        n_valid = 0\n",
    "\n",
    "        for b in range(B):\n",
    "            src_feat = src_features[b]  # (H_s, W_s, D)\n",
    "            tgt_feat = tgt_features[b]  # (H_t, W_t, D)\n",
    "            src_kp = src_kps[b]  # (N, 2)\n",
    "            tgt_kp = tgt_kps[b]  # (N, 2)\n",
    "            valid = valid_mask[b]  # (N,)\n",
    "\n",
    "            if valid.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            # Filter valid keypoints\n",
    "            src_kp_valid = src_kp[valid]\n",
    "            tgt_kp_valid = tgt_kp[valid]\n",
    "\n",
    "            # Convert to patch coordinates\n",
    "            src_kp_patch = (src_kp_valid / patch_size).long()\n",
    "            tgt_kp_patch = (tgt_kp_valid / patch_size).long()\n",
    "\n",
    "            H_s, W_s, D = src_feat.shape\n",
    "            H_t, W_t, _ = tgt_feat.shape\n",
    "\n",
    "            # Clamp coordinates\n",
    "            src_kp_patch[:, 0] = src_kp_patch[:, 0].clamp(0, W_s - 1)\n",
    "            src_kp_patch[:, 1] = src_kp_patch[:, 1].clamp(0, H_s - 1)\n",
    "            tgt_kp_patch[:, 0] = tgt_kp_patch[:, 0].clamp(0, W_t - 1)\n",
    "            tgt_kp_patch[:, 1] = tgt_kp_patch[:, 1].clamp(0, H_t - 1)\n",
    "\n",
    "            # Extract features at keypoint locations\n",
    "            N = src_kp_valid.shape[0]\n",
    "            for i in range(N):\n",
    "                src_x, src_y = src_kp_patch[i]\n",
    "                tgt_x, tgt_y = tgt_kp_patch[i]\n",
    "\n",
    "                src_vec = src_feat[src_y, src_x]  # (D,)\n",
    "                tgt_vec = tgt_feat[tgt_y, tgt_x]  # (D,)\n",
    "\n",
    "                if self.loss_type == 'cosine':\n",
    "                    # Maximize cosine similarity\n",
    "                    similarity = F.cosine_similarity(\n",
    "                        src_vec.unsqueeze(0), tgt_vec.unsqueeze(0), dim=1\n",
    "                    )\n",
    "                    loss = 1.0 - similarity\n",
    "\n",
    "                elif self.loss_type == 'l2':\n",
    "                    # Minimize L2 distance\n",
    "                    loss = F.mse_loss(src_vec, tgt_vec)\n",
    "\n",
    "                elif self.loss_type == 'contrastive':\n",
    "                    # Positive: corresponding point\n",
    "                    pos_sim = F.cosine_similarity(\n",
    "                        src_vec.unsqueeze(0), tgt_vec.unsqueeze(0), dim=1\n",
    "                    )\n",
    "\n",
    "                    # Negatives: sample random points from target\n",
    "                    neg_indices = torch.randint(\n",
    "                        0, H_t * W_t, (8,), device=src_vec.device\n",
    "                    )\n",
    "                    tgt_flat = tgt_feat.reshape(-1, D)\n",
    "                    neg_vecs = tgt_flat[neg_indices]  # (8, D)\n",
    "\n",
    "                    neg_sim = F.cosine_similarity(\n",
    "                        src_vec.unsqueeze(0).expand(8, -1),\n",
    "                        neg_vecs,\n",
    "                        dim=1\n",
    "                    )\n",
    "\n",
    "                    # InfoNCE-style loss\n",
    "                    pos_exp = torch.exp(pos_sim / self.temperature)\n",
    "                    neg_exp = torch.exp(neg_sim / self.temperature).sum()\n",
    "\n",
    "                    loss = -torch.log(pos_exp / (pos_exp + neg_exp))\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown loss type: {self.loss_type}\")\n",
    "\n",
    "                total_loss += loss\n",
    "                n_valid += 1\n",
    "\n",
    "        if n_valid == 0:\n",
    "            return torch.tensor(0.0, device=src_features.device, requires_grad=True)\n",
    "\n",
    "        return total_loss / n_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a05f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T09:32:36.036666Z",
     "iopub.status.busy": "2026-01-25T09:32:36.036023Z",
     "iopub.status.idle": "2026-01-25T09:32:36.066054Z",
     "shell.execute_reply": "2026-01-25T09:32:36.065175Z",
     "shell.execute_reply.started": "2026-01-25T09:32:36.036625Z"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1769274252081,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "448a05f2",
    "outputId": "02491ab4-d2d3-4902-f486-3b10a95ad821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss: contrastive\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELLA 6: Trainable Backbone Wrapper (DINOv2 / DINOv3 / SAM) + Loss\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "class FinetunableBackbone(nn.Module):\n",
    "    \"\"\"\n",
    "    Unified wrapper:\n",
    "    - Loads extractor (DINOv2 / DINOv3 / SAM)\n",
    "    - Freezes all params\n",
    "    - Unfreezes last N transformer blocks\n",
    "    - Optionally enables gradient checkpointing (best-effort, depending on backbone impl)\n",
    "    - Returns features as (B, H, W, D)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_name: str,\n",
    "        num_layers_to_finetune: int,\n",
    "        device: str,\n",
    "        use_gradient_checkpointing: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.backbone_name = backbone_name\n",
    "        self.num_layers_to_finetune = num_layers_to_finetune\n",
    "        self.device = device\n",
    "\n",
    "        # -------------------------\n",
    "        # Load extractor\n",
    "        # -------------------------\n",
    "        if backbone_name.startswith(\"dinov2\"):\n",
    "            self.extractor = DINOv2Extractor(variant=backbone_name, device=device)\n",
    "            self._model_for_unfreeze = self.extractor.model\n",
    "        elif backbone_name.startswith(\"dinov3\"):\n",
    "            self.extractor = DINOv3Extractor(variant=backbone_name, device=device)\n",
    "            self._model_for_unfreeze = self.extractor.model\n",
    "        elif backbone_name.startswith(\"sam\"):\n",
    "            variant = backbone_name.replace(\"sam_\", \"\")  # vit_b / vit_l / vit_h\n",
    "            self.extractor = SAMImageEncoder(variant=variant, device=device, allow_hub_download=True)\n",
    "            self._model_for_unfreeze = self.extractor.model.image_encoder\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone_name: {backbone_name}\")\n",
    "\n",
    "        self.stride = self.extractor.stride\n",
    "\n",
    "        # Freeze all\n",
    "        for p in self.extractor.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Unfreeze last blocks\n",
    "        self._unfreeze_last_blocks(num_layers_to_finetune)\n",
    "\n",
    "        # Enable gradient checkpointing (best-effort)\n",
    "        self._enable_gradient_checkpointing(use_gradient_checkpointing)\n",
    "\n",
    "        # Infer feature dim with a tiny forward\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros((1, 3, 224, 224), device=self.device)\n",
    "            feat_map, _ = self.extractor.extract_feats(dummy)\n",
    "            self.feat_dim = int(feat_map.shape[-1])\n",
    "\n",
    "        n_trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        n_total = sum(p.numel() for p in self.parameters())\n",
    "\n",
    "        print(\"\\n Model summary:\")\n",
    "        print(f\"  Backbone: {backbone_name}\")\n",
    "        print(f\"  Stride:   {self.stride}\")\n",
    "        print(f\"  Feat dim: {self.feat_dim}\")\n",
    "        print(f\"  Trainable params: {n_trainable:,} / {n_total:,} ({(n_trainable/n_total*100 if n_total else 0):.2f}%)\\n\")\n",
    "\n",
    "    def _get_blocks(self):\n",
    "        m = self._model_for_unfreeze\n",
    "        if hasattr(m, \"blocks\"):\n",
    "            return m.blocks\n",
    "        if hasattr(m, \"encoder\") and hasattr(m.encoder, \"layers\"):\n",
    "            return m.encoder.layers\n",
    "        return None\n",
    "\n",
    "    def _unfreeze_last_blocks(self, num_layers: int):\n",
    "        if num_layers <= 0:\n",
    "            print(\"\\n Unfreezing: none (frozen backbone)\\n\")\n",
    "            return\n",
    "\n",
    "        blocks = self._get_blocks()\n",
    "        if blocks is None:\n",
    "            raise AttributeError(\"Cannot find transformer blocks to unfreeze in the selected backbone.\")\n",
    "\n",
    "        total = len(blocks)\n",
    "        start = max(0, total - num_layers)\n",
    "        print(f\"\\n Unfreezing last {num_layers} blocks: [{start}..{total-1}] out of {total}\\n\")\n",
    "\n",
    "        for i in range(start, total):\n",
    "            for p in blocks[i].parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "    def _enable_gradient_checkpointing(self, enabled: bool):\n",
    "        if not enabled:\n",
    "            return\n",
    "\n",
    "        m = self._model_for_unfreeze\n",
    "\n",
    "        tried = []\n",
    "        if hasattr(m, \"gradient_checkpointing_enable\"):\n",
    "            tried.append(\"gradient_checkpointing_enable\")\n",
    "            try:\n",
    "                m.gradient_checkpointing_enable()\n",
    "                print(\"‚úì Gradient checkpointing enabled via .gradient_checkpointing_enable()\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"! gradient_checkpointing_enable failed: {e}\")\n",
    "\n",
    "        if hasattr(m, \"set_grad_checkpointing\"):\n",
    "            tried.append(\"set_grad_checkpointing\")\n",
    "            try:\n",
    "                m.set_grad_checkpointing(True)\n",
    "                print(\"‚úì Gradient checkpointing enabled via .set_grad_checkpointing(True)\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"! set_grad_checkpointing failed: {e}\")\n",
    "\n",
    "        if hasattr(m, \"set_gradient_checkpointing\"):\n",
    "            tried.append(\"set_gradient_checkpointing\")\n",
    "            try:\n",
    "                m.set_gradient_checkpointing(True)\n",
    "                print(\"‚úì Gradient checkpointing enabled via .set_gradient_checkpointing(True)\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"! set_gradient_checkpointing failed: {e}\")\n",
    "\n",
    "        if hasattr(m, \"use_checkpoint\"):\n",
    "            tried.append(\"use_checkpoint\")\n",
    "            try:\n",
    "                m.use_checkpoint = True\n",
    "                print(\"‚úì Gradient checkpointing enabled via .use_checkpoint=True\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                print(f\"! use_checkpoint flag failed: {e}\")\n",
    "\n",
    "        print(\"! Gradient checkpointing requested but no supported API was found on this backbone.\")\n",
    "        if tried:\n",
    "            print(\"  Tried:\", tried)\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        feat_map, _ = self.extractor.extract_feats(image)\n",
    "        return feat_map\n",
    "\n",
    "# Loss (repo)\n",
    "criterion = CorrespondenceLoss(loss_type=config.loss_type, temperature=config.temperature).to(device)\n",
    "print(\" Loss:\", config.loss_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6bf48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T09:32:36.067476Z",
     "iopub.status.busy": "2026-01-25T09:32:36.067180Z",
     "iopub.status.idle": "2026-01-25T09:32:36.232235Z",
     "shell.execute_reply": "2026-01-25T09:32:36.231193Z",
     "shell.execute_reply.started": "2026-01-25T09:32:36.067451Z"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1769274252402,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "b4e6bf48",
    "outputId": "aaaf7442-229f-4ee1-de32-f3fff85555cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SPAIR_ROOT: /home/jupyter/AML/dataset/Spair-71k\n",
      " Loaded 53340 pairs from train split (large)\n",
      " Loaded 5384 pairs from val split (large)\n",
      " Loaded 12234 pairs from test split (large)\n",
      " Train pairs: 20000 | batches: 20000\n",
      "   Val pairs: 500 | batches: 500\n",
      "  Test pairs: 12234 | batches: 12234\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELLA 7: DataLoaders (train/val)\n",
    "# ============================================================================\n",
    "\n",
    "def maybe_subset(ds, max_pairs):\n",
    "    if max_pairs is None:\n",
    "        return ds\n",
    "    idx = torch.randperm(len(ds))[:max_pairs].tolist()\n",
    "    return torch.utils.data.Subset(ds, idx)\n",
    "\n",
    "train_dataset_full = SPairDataset(\n",
    "    root=SPAIR_ROOT, split='train', size='large', long_side=IMG_SIZE,\n",
    "    normalize=True, load_segmentation=False\n",
    ")\n",
    "val_dataset_full = SPairDataset(\n",
    "    root=SPAIR_ROOT, split='val', size='large', long_side=IMG_SIZE,\n",
    "    normalize=True, load_segmentation=False\n",
    ")\n",
    "\n",
    "train_ds = maybe_subset(train_dataset_full, config.max_train_pairs)\n",
    "val_ds   = maybe_subset(val_dataset_full, config.max_val_pairs)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers,\n",
    "    pin_memory=torch.cuda.is_available(), drop_last=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers,\n",
    "    pin_memory=torch.cuda.is_available(), drop_last=False\n",
    ")\n",
    "print(f\" Train pairs: {len(train_ds)} | batches: {len(train_loader)}\")\n",
    "print(f\"   Val pairs: {len(val_ds)} | batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6af126",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-25T09:32:36.233930Z",
     "iopub.status.busy": "2026-01-25T09:32:36.233544Z",
     "iopub.status.idle": "2026-01-25T09:32:36.241211Z",
     "shell.execute_reply": "2026-01-25T09:32:36.240282Z",
     "shell.execute_reply.started": "2026-01-25T09:32:36.233900Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1769274252409,
     "user": {
      "displayName": "Francesco Alzate",
      "userId": "15701221883649199981"
     },
     "user_tz": -60
    },
    "id": "fc6af126",
    "outputId": "3df893e8-80c8-483c-b254-72b46a97fb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Eval helpers ready (using UnifiedEvaluator + CorrespondenceMatcher).\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELLA 8: Evaluation helpers ‚Äî Using UnifiedEvaluator + CorrespondenceMatcher\n",
    "# ============================================================================\n",
    "\n",
    "class FinetunableBackboneAdapter:\n",
    "    \"\"\"Adapter per usare FinetunableBackbone con CorrespondenceMatcher.\"\"\"\n",
    "    def __init__(self, finetunable_backbone):\n",
    "        self.model = finetunable_backbone\n",
    "        self.device = finetunable_backbone.device\n",
    "        self.config = type('obj', (object,), {'patch_size': finetunable_backbone.stride})()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, img):\n",
    "        \"\"\"Adatta (B, H, W, D) ‚Üí (H, W, D) per compatibilit√† con CorrespondenceMatcher.\"\"\"\n",
    "        feat = self.model(img)  # (B, H, W, D)\n",
    "        return feat.squeeze(0),  # (H, W, D), restituisce tupla come expected\n",
    "\n",
    "evaluator = UnifiedEvaluator(\n",
    "    dataloader=val_loader,\n",
    "    device=device,\n",
    "    thresholds=[0.05, 0.10, 0.15, 0.20]\n",
    ")\n",
    "\n",
    "print(\" Eval helpers ready (using UnifiedEvaluator + CorrespondenceMatcher).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3278fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELLA 10: Training Loop (AMP + Warmup + Grad Clip + TB + Resume + Val modes)\n",
    "# ============================================================================\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import LinearLR, SequentialLR, CosineAnnealingLR\n",
    "\n",
    "# -------------------------\n",
    "# Build finetunable model\n",
    "# -------------------------\n",
    "model = FinetunableBackbone(\n",
    "    backbone_name=config.backbone_name,\n",
    "    num_layers_to_finetune=config.num_layers_to_finetune,\n",
    "    device=device,\n",
    "    use_gradient_checkpointing=config.use_gradient_checkpointing,\n",
    ").to(device)\n",
    "\n",
    "# -------------------------\n",
    "# Optimizer\n",
    "# -------------------------\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "if len(trainable_params) == 0:\n",
    "    raise RuntimeError(\"No trainable parameters found. Check num_layers_to_finetune > 0.\")\n",
    "\n",
    "optimizer = optim.AdamW(trainable_params, lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "\n",
    "# -------------------------\n",
    "# Scheduler: warmup -> cosine (step-based, matches main.ipynb style)\n",
    "# -------------------------\n",
    "total_updates = max(1, (len(train_loader) * config.num_epochs) // config.gradient_accumulation_steps)\n",
    "warmup_updates = max(1, (len(train_loader) * config.warmup_epochs) // config.gradient_accumulation_steps)\n",
    "\n",
    "warmup = LinearLR(optimizer, start_factor=0.1, total_iters=warmup_updates)\n",
    "cosine = CosineAnnealingLR(optimizer, T_max=max(1, total_updates - warmup_updates))\n",
    "scheduler = SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_updates])\n",
    "\n",
    "# AMP\n",
    "use_amp = bool(config.use_amp and torch.cuda.is_available())\n",
    "scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "print(f\" AMP: {use_amp} | Grad accumulation: {config.gradient_accumulation_steps} | Grad checkpointing: {config.use_gradient_checkpointing}\")\n",
    "\n",
    "# TensorBoard\n",
    "tb_writer = None\n",
    "if config.use_tensorboard:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    logdir = Path(config.tb_logdir) / config.run_name\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "    tb_writer = SummaryWriter(log_dir=str(logdir))\n",
    "    print(f\" TensorBoard logdir: {logdir}\")\n",
    "\n",
    "# -------------------------\n",
    "# Checkpointing (complete state for resume)\n",
    "# -------------------------\n",
    "best_pck = -1.0\n",
    "start_epoch = 0\n",
    "global_step = 0\n",
    "best_path = Path(config.save_dir) / f\"finetuned_{config.run_name}.pt\"\n",
    "best_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_ckpt(path: Path, epoch: int, best_pck_val: float):\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"global_step\": global_step,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"scaler_state_dict\": scaler.state_dict() if use_amp else None,\n",
    "        \"best_pck@0.10\": best_pck_val,\n",
    "        \"config\": config.__dict__,\n",
    "        \"baseline_val_slice_pck\": baseline_pck,\n",
    "        \"baseline_val_slice_loss\": baseline_vloss,\n",
    "    }, str(path))\n",
    "\n",
    "if config.training_mode == \"resume\":\n",
    "    ckpt_path = config.resume_checkpoint or str(best_path)\n",
    "    if ckpt_path and os.path.exists(ckpt_path):\n",
    "        print(f\"\\nüîß Resuming from checkpoint: {ckpt_path}\")\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "        model.load_state_dict(ckpt[\"model_state_dict\"], strict=True)\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])\n",
    "        scheduler.load_state_dict(ckpt[\"scheduler_state_dict\"])\n",
    "        if use_amp and ckpt.get(\"scaler_state_dict\") is not None:\n",
    "            scaler.load_state_dict(ckpt[\"scaler_state_dict\"])\n",
    "        start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
    "        global_step = int(ckpt.get(\"global_step\", 0))\n",
    "        best_pck = float(ckpt.get(\"best_pck@0.10\", best_pck))\n",
    "        print(f\"   ‚úì start_epoch={start_epoch} | global_step={global_step} | best_pck@0.10={best_pck:.2f}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è resume requested but checkpoint not found: {ckpt_path}\")\n",
    "        print(\"   Continuing from current weights in memory.\")\n",
    "elif config.training_mode == \"fresh\":\n",
    "    print(\"\\nüîß Training mode: fresh (starting from pretrained weights loaded by backbone extractor)\")\n",
    "else:\n",
    "    print(\"\\nüîß Training mode: continue (keeping current weights in memory)\")\n",
    "\n",
    "# -------------------------\n",
    "# Intra-epoch log checkpoints\n",
    "# -------------------------\n",
    "def get_log_steps(n_batches: int, k: int):\n",
    "    if k <= 0:\n",
    "        return set()\n",
    "    if n_batches <= 1:\n",
    "        return {0}\n",
    "    steps = set(int(round(x)) for x in np.linspace(0, n_batches - 1, k))\n",
    "    return steps\n",
    "\n",
    "log_steps = get_log_steps(len(train_loader), config.log_checkpoints_per_epoch)\n",
    "\n",
    "# -------------------------\n",
    "# Helper: evaluation with visible progress + final print\n",
    "# -------------------------\n",
    "@torch.no_grad()\n",
    "def eval_metrics_visible(model, loader, alphas=(0.05, 0.1, 0.2), max_batches=None, compute_loss=True, desc=\"Eval\"):\n",
    "    \"\"\"\n",
    "    Same as eval_metrics, but tqdm total matches max_batches so it doesn't look like it \"stops early\".\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    agg = {a: {\"correct\": 0, \"valid\": 0} for a in alphas}\n",
    "    losses = []\n",
    "\n",
    "    total = len(loader) if max_batches is None else min(len(loader), max_batches)\n",
    "    for bi, batch in enumerate(tqdm(loader, total=total, desc=desc, leave=False)):\n",
    "        if max_batches is not None and bi >= max_batches:\n",
    "            break\n",
    "\n",
    "        src = batch[\"src_img\"].to(device)\n",
    "        tgt = batch[\"tgt_img\"].to(device)\n",
    "        src_kps = batch[\"src_kps\"].to(device)\n",
    "        tgt_kps = batch[\"tgt_kps\"].to(device)\n",
    "        vm = batch[\"valid_mask\"].to(device)\n",
    "\n",
    "        src_feat = model(src)\n",
    "        tgt_feat = model(tgt)\n",
    "\n",
    "        if compute_loss:\n",
    "            loss = criterion(src_feat, tgt_feat, src_kps, tgt_kps, vm, patch_size=model.stride)\n",
    "            losses.append(float(loss.item()))\n",
    "\n",
    "        pred = predict_argmax(src_feat, tgt_feat, src_kps, vm, model.stride)\n",
    "\n",
    "        pred_np = pred.cpu().numpy()\n",
    "        tgt_np = tgt_kps.cpu().numpy()\n",
    "        vm_np = vm.cpu().numpy()\n",
    "\n",
    "        for b in range(pred_np.shape[0]):\n",
    "            for a in alphas:\n",
    "                pck, n_valid = compute_pck(pred_np[b], tgt_np[b], vm_np[b], alpha=a)\n",
    "                correct = int(round(pck * n_valid / 100.0))\n",
    "                agg[a][\"correct\"] += correct\n",
    "                agg[a][\"valid\"] += n_valid\n",
    "\n",
    "    out = {}\n",
    "    for a in alphas:\n",
    "        v = agg[a][\"valid\"]\n",
    "        out[a] = 0.0 if v == 0 else (agg[a][\"correct\"] / v) * 100.0\n",
    "\n",
    "    avg_loss = None if (not compute_loss or len(losses) == 0) else float(np.mean(losses))\n",
    "    return out, avg_loss\n",
    "\n",
    "# -------------------------\n",
    "# One epoch\n",
    "# -------------------------\n",
    "def train_one_epoch(epoch: int):\n",
    "    global global_step\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    pbar = tqdm(train_loader, desc=f\"Train {epoch+1}/{config.num_epochs}\", leave=False)\n",
    "\n",
    "    accumulated = 0\n",
    "\n",
    "    for step, batch in enumerate(pbar):\n",
    "        src = batch[\"src_img\"].to(device, non_blocking=True)\n",
    "        tgt = batch[\"tgt_img\"].to(device, non_blocking=True)\n",
    "        src_kps = batch[\"src_kps\"].to(device, non_blocking=True)\n",
    "        tgt_kps = batch[\"tgt_kps\"].to(device, non_blocking=True)\n",
    "        vm = batch[\"valid_mask\"].to(device, non_blocking=True)\n",
    "\n",
    "        with autocast(enabled=use_amp):\n",
    "            src_feat = model(src)\n",
    "            tgt_feat = model(tgt)\n",
    "            loss = criterion(src_feat, tgt_feat, src_kps, tgt_kps, vm, patch_size=model.stride)\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        accumulated += 1\n",
    "\n",
    "        do_update = (accumulated == config.gradient_accumulation_steps) or (step + 1 == len(train_loader))\n",
    "\n",
    "        if do_update:\n",
    "            if config.grad_clip_norm is not None and config.grad_clip_norm > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip_norm)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            scheduler.step()\n",
    "            accumulated = 0\n",
    "            global_step += 1\n",
    "\n",
    "        epoch_losses.append(float(loss.item() * config.gradient_accumulation_steps))\n",
    "        pbar.set_postfix({\"loss\": f\"{np.mean(epoch_losses):.4f}\", \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"})\n",
    "\n",
    "        # ---- Intra-epoch logging + VISIBLE eval summary\n",
    "        if config.use_wandb and (step in log_steps) and (step > 0):\n",
    "            avg_train_loss = float(np.mean(epoch_losses)) if len(epoch_losses) else 0.0\n",
    "\n",
    "            t_eval0 = time.time()\n",
    "            vpck, vloss = eval_metrics_visible(\n",
    "                model,\n",
    "                val_loader,\n",
    "                alphas=(0.05, 0.10, 0.20),\n",
    "                max_batches=config.val_slice_max_batches,\n",
    "                compute_loss=True,\n",
    "                desc=\"Eval (val-slice)\"\n",
    "            )\n",
    "            t_eval = time.time() - t_eval0\n",
    "\n",
    "            # Print a compact progress line so you see the result even if tqdm rendering is weird\n",
    "            print(\n",
    "                f\"[Intra-epoch eval] epoch={epoch+1} step={step+1}/{len(train_loader)} | \"\n",
    "                f\"val_loss={vloss:.4f} | PCK@0.10={vpck.get(0.10, 0.0):.2f} | {t_eval:.1f}s\"\n",
    "            )\n",
    "\n",
    "            wandb.log({\n",
    "                \"training loss\": avg_train_loss,\n",
    "                \"validation loss\": vloss if vloss is not None else 0.0,\n",
    "                \"validation pck\": vpck.get(0.10, 0.0),\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"batch\": step + 1,\n",
    "                \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "            })\n",
    "\n",
    "            model.train()\n",
    "\n",
    "    return float(np.mean(epoch_losses)) if len(epoch_losses) else 0.0\n",
    "\n",
    "print(\"\\n Starting fine-tuning...\\n\")\n",
    "\n",
    "for epoch in range(start_epoch, config.num_epochs):\n",
    "    t0 = time.time()\n",
    "    train_loss = train_one_epoch(epoch)\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    # Validation per config.val_mode\n",
    "    val_out = run_validation(model, config.val_mode, epoch)\n",
    "\n",
    "    # Choose checkpoint selection metric: prefer FULL when available, otherwise slice\n",
    "    if config.val_mode in (\"full\", \"slice\"):\n",
    "        score = val_out[\"pck\"][0.10]\n",
    "        val_loss = val_out[\"loss\"]\n",
    "    else:  # hybrid\n",
    "        if \"pck_full\" in val_out:\n",
    "            score = val_out[\"pck_full\"][0.10]\n",
    "            val_loss = val_out[\"loss_full\"]\n",
    "        else:\n",
    "            score = val_out[\"pck\"][0.10]\n",
    "            val_loss = val_out[\"loss\"]\n",
    "\n",
    "    print(f\"\\n Epoch {epoch+1}/{config.num_epochs} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | PCK@0.10={score:.2f} | {dt:.1f}s\")\n",
    "\n",
    "    # TensorBoard\n",
    "    if tb_writer is not None:\n",
    "        tb_writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "        tb_writer.add_scalar(\"val/pck@0.10\", score, epoch)\n",
    "        if val_loss is not None:\n",
    "            tb_writer.add_scalar(\"val/loss\", val_loss, epoch)\n",
    "\n",
    "    # wandb end-of-epoch logging (main.ipynb style)\n",
    "    if config.use_wandb:\n",
    "        wandb.log({\n",
    "            \"training loss\": train_loss,\n",
    "            \"validation loss\": val_loss if val_loss is not None else 0.0,\n",
    "            \"validation pck\": score,\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"batch\": len(train_loader),\n",
    "            \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "        })\n",
    "\n",
    "    # Save best checkpoint\n",
    "    if score > best_pck:\n",
    "        best_pck = score\n",
    "        save_ckpt(best_path, epoch, best_pck)\n",
    "        print(f\"  ‚úî Saved best checkpoint: {best_path} (PCK@0.10={best_pck:.2f})\")\n",
    "\n",
    "print(\"\\n Fine-tuning done.\")\n",
    "print(\" Best PCK@0.10:\", best_pck)\n",
    "\n",
    "if tb_writer is not None:\n",
    "    tb_writer.close()\n",
    "\n",
    "# finish wandb run (if needed)\n",
    "if config.use_wandb:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m138",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m138"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
