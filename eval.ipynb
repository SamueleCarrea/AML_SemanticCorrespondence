{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 1: Setup Progetto (usando struttura esistente)\n",
        "# ============================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\" AML Semantic Correspondence - Training-Free Baseline\\n\")\n",
        "\n",
        "# 1. Mount Google Drive (se non già montato)\n",
        "if not Path('/content/drive').exists():\n",
        "    drive.mount('/content/drive')\n",
        "    print(\" Google Drive mounted\\n\")\n",
        "else:\n",
        "    print(\" Google Drive already mounted\\n\")\n",
        "\n",
        "# 2. Usa la tua struttura esistente\n",
        "PROJECT_ROOT = '/content/drive/MyDrive/AML'\n",
        "DATA_DIR = f'{PROJECT_ROOT}/data'\n",
        "CHECKPOINT_DIR = f'{PROJECT_ROOT}/checkpoints'\n",
        "RESULTS_DIR = f'{PROJECT_ROOT}/results'\n",
        "\n",
        "# 3. Clone/Copy repository files\n",
        "REPO_DIR = 'https://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@github.com/SamueleCarrea/AML_SemanticCorrespondence'\n",
        "LOCAL_REPO_DIR = 'AML_SemanticCorrespondence'\n",
        "\n",
        "\n",
        "if not Path(REPO_DIR).exists():\n",
        "    print(\"\\n Cloning repository...\")\n",
        "    !git clone {REPO_DIR}\n",
        "    print(\" Repository cloned\")\n",
        "else:\n",
        "    print(\"\\n Repository exists\")\n",
        "\n",
        "# Aggiungi al path\n",
        "sys.path.insert(0, LOCAL_REPO_DIR)\n",
        "\n",
        "# 4. Verifica GPU\n",
        "import torch\n",
        "print(f\"\\n  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "print(\"\\n Setup complete!\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj-JAohKd36B",
        "outputId": "9847a58b-da8d-4274-8295-042a489ac179"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " AML Semantic Correspondence - Training-Free Baseline\n",
            "\n",
            " Google Drive already mounted\n",
            "\n",
            "\n",
            " Cloning repository...\n",
            "fatal: destination path 'AML_SemanticCorrespondence' already exists and is not an empty directory.\n",
            " Repository cloned\n",
            "\n",
            "  GPU: Tesla T4\n",
            "   VRAM: 15.8 GB\n",
            "\n",
            " Setup complete!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 2: Install Dependencies\n",
        "# ============================================================================\n",
        "\n",
        "print(\" Installing dependencies...\\n\")\n",
        "\n",
        "# Installa da requirements.txt clonato\n",
        "!pip install -q -r {LOCAL_REPO_DIR}/requirements.txt\n",
        "\n",
        "# Verifica veloce\n",
        "import torch\n",
        "print(f\"\\n PyTorch {torch.__version__}\")\n",
        "print(f\" CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "print(\" Dependencies installed!\\n\")"
      ],
      "metadata": {
        "id": "szECarDEfY7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc48c45-8e14-4f09-b701-5847b0c17f0c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Installing dependencies...\n",
            "\n",
            "\n",
            " PyTorch 2.9.0+cu126\n",
            " CUDA available: True\n",
            " Dependencies installed!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 3: Load SPair-71k Dataset\n",
        "# ============================================================================\n",
        "\n",
        "from dataset.spair import SPairDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "\n",
        "SPAIR_ROOT = f'{DATA_DIR}/SPair-71k'\n",
        "\n",
        "if not Path(SPAIR_ROOT).exists():\n",
        "    raise FileNotFoundError(f\"Dataset not found: {SPAIR_ROOT}\")\n",
        "\n",
        "# Load dataset\n",
        "test_dataset = SPairDataset(\n",
        "    root=SPAIR_ROOT,\n",
        "    split='test',\n",
        "    long_side=518,\n",
        "    normalize=True\n",
        ")\n",
        "\n",
        "# DataLoader\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "# Sanity check\n",
        "sample = test_dataset[0]\n",
        "print(f\" Loaded {len(test_dataset)} pairs | Sample: {sample['pair_id']} {sample['src_img'].shape}\\n\")"
      ],
      "metadata": {
        "id": "ZyWnOAFugfAp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9cc6c275-8d50-4d17-c14e-1092e1fab7a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2789113486.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspair\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSPairDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/AML_SemanticCorrespondence/dataset/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspair\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSPairDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"SPairDataset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/AML_SemanticCorrespondence/dataset/spair.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgiou_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneralized_box_iou_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSqueezeExcitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/roi_align.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_compile_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0maot_compile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/aot_compile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecompile_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrecompileContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackTrigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObservedException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         )\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 4: Unified Backbone Registry & Factory\n",
        "# ============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Dict, Tuple\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class BackboneConfig:\n",
        "    \"\"\"Configuration for a vision backbone.\"\"\"\n",
        "    name: str\n",
        "    patch_size: int\n",
        "    embed_dim: int\n",
        "    hub_name: str  # Nome per torch.hub o path checkpoint\n",
        "    type: str  # 'dinov2', 'dinov3', 'sam'\n",
        "\n",
        "\n",
        "# Registry di tutti i backbones supportati\n",
        "BACKBONE_REGISTRY = {\n",
        "    # DINOv2 variants\n",
        "    'dinov2_vitb14': BackboneConfig('DINOv2-ViT-B/14', 14, 768, 'dinov2_vitb14', 'dinov2'),\n",
        "    # DINOv3 (quando disponibile, per ora usa DINOv2)\n",
        "    'dinov3_vitb16': BackboneConfig('DINOv3-ViT-B/16', 16, 768, 'dinov3_vitb16', 'dinov3'),\n",
        "    # SAM variants (opzionale)\n",
        "    'sam_vit_b': BackboneConfig('SAM-ViT-B', 16, 768, 'vit_b', 'sam'),\n",
        "}\n",
        "\n",
        "\n",
        "class UnifiedBackbone(nn.Module):\n",
        "    \"\"\"Unified interface per tutti i backbones.\"\"\"\n",
        "\n",
        "    def __init__(self, backbone_name: str, device: str = 'cuda'):\n",
        "        super().__init__()\n",
        "\n",
        "        if backbone_name not in BACKBONE_REGISTRY:\n",
        "            raise ValueError(f\"Unknown backbone: {backbone_name}. Available: {list(BACKBONE_REGISTRY.keys())}\")\n",
        "\n",
        "        self.config = BACKBONE_REGISTRY[backbone_name]\n",
        "        self.device = device\n",
        "\n",
        "        print(f\" Loading {self.config.name}...\")\n",
        "\n",
        "        # Load model based on type\n",
        "        if self.config.type == 'dinov2':\n",
        "            self.model = self._load_dinov2()\n",
        "        elif self.config.type == 'dinov3':\n",
        "            self.model = self._load_dinov3()\n",
        "        elif self.config.type == 'sam':\n",
        "            self.model = self._load_sam()\n",
        "        else:\n",
        "            raise NotImplementedError(f\"Type {self.config.type} not implemented\")\n",
        "\n",
        "        self.model.eval()\n",
        "        self.model.to(device)\n",
        "\n",
        "        print(f\" {self.config.name} loaded\")\n",
        "        print(f\"   Patch size: {self.config.patch_size}\")\n",
        "        print(f\"   Embedding: {self.config.embed_dim}D\\n\")\n",
        "\n",
        "    def _load_dinov2(self):\n",
        "        \"\"\"Load DINOv2 from torch.hub.\"\"\"\n",
        "\n",
        "        return torch.hub.load( 'facebookresearch/dinov2', self.config.hub_name,pretrained=True,verbose=False)\n",
        "\n",
        "    def _load_dinov3(self):\n",
        "        \"\"\"Load DINOv3 from torch.hub.\"\"\"\n",
        "\n",
        "        return torch.hub.load(REPO_DIR, 'dinov3_vitb16', source='local', weights=<CHECKPOINT/URL/OR/PATH>)\n",
        "\n",
        "\n",
        "    def _load_sam(self):\n",
        "        \"\"\"Load SAM (placeholder - requires segment-anything package).\"\"\"\n",
        "        try:\n",
        "            from segment_anything import sam_model_registry\n",
        "            checkpoint_path = f'/tmp/sam_{self.config.hub_name}.pth'\n",
        "\n",
        "            # Download if needed\n",
        "            if not Path(checkpoint_path).exists():\n",
        "                urls = {\n",
        "                    'vit_b': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth',\n",
        "                }\n",
        "                torch.hub.download_url_to_file(urls[self.config.hub_name], checkpoint_path)\n",
        "\n",
        "            return sam_model_registry[self.config.hub_name](checkpoint=checkpoint_path)\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"  SAM requires: pip install git+https://github.com/facebookresearch/segment-anything.git\")\n",
        "            raise\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def extract_features(self, image: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Extract dense features.\n",
        "\n",
        "        Args:\n",
        "            image: (B, 3, H, W)\n",
        "        Returns:\n",
        "            features: (B, H_patches, W_patches, D)\n",
        "        \"\"\"\n",
        "        B, C, H, W = image.shape\n",
        "        image = image.to(self.device)\n",
        "\n",
        "        if self.config.type == 'dinov2':\n",
        "            # DINOv2 extraction\n",
        "            output = self.model.forward_features(image)\n",
        "            patch_tokens = output['x_norm_patchtokens']  # (B, N, D)\n",
        "\n",
        "            H_p = H // self.config.patch_size\n",
        "            W_p = W // self.config.patch_size\n",
        "\n",
        "            features = patch_tokens.view(B, H_p, W_p, self.config.embed_dim)\n",
        "\n",
        "        elif self.config.type == 'sam':\n",
        "            # SAM extraction\n",
        "            features = self.model.image_encoder(\n",
        "                F.interpolate(image, size=(1024, 1024), mode='bilinear')\n",
        "            )\n",
        "            # Resize back and permute\n",
        "            H_p = H // self.config.patch_size\n",
        "            W_p = W // self.config.patch_size\n",
        "            features = F.interpolate(features, size=(H_p, W_p), mode='bilinear')\n",
        "            features = features.permute(0, 2, 3, 1)\n",
        "\n",
        "        return features\n",
        "\n",
        "\n",
        "# Test registry\n",
        "print(\" Available Backbones:\")\n",
        "print(\"=\" * 60)\n",
        "for name, config in BACKBONE_REGISTRY.items():\n",
        "    print(f\"   {name:20s} → {config.name}\")\n",
        "print(\"=\" * 60)\n",
        "print()"
      ],
      "metadata": {
        "id": "DQfunoH8gjHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "347e6bfd-1a5f-482d-e5ff-118ebf06ec8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 68)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m68\u001b[0m\n\u001b[0;31m    def _load_dinov3(self):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 5: Unified Correspondence Matcher\n",
        "# ============================================================================\n",
        "\n",
        "class CorrespondenceMatcher:\n",
        "    \"\"\"Semantic correspondence matcher (training-free baseline).\"\"\"\n",
        "\n",
        "    def __init__(self, backbone: UnifiedBackbone):\n",
        "        self.backbone = backbone\n",
        "        self.device = backbone.device\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def match(\n",
        "        self,\n",
        "        src_img: torch.Tensor,\n",
        "        tgt_img: torch.Tensor,\n",
        "        src_kps: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Find correspondences for source keypoints.\n",
        "\n",
        "        Args:\n",
        "            src_img: (1, 3, H, W)\n",
        "            tgt_img: (1, 3, H, W)\n",
        "            src_kps: (N, 2) in pixel coords (x, y)\n",
        "\n",
        "        Returns:\n",
        "            tgt_kps_pred: (N, 2) predicted target keypoints\n",
        "        \"\"\"\n",
        "        # Extract features\n",
        "        src_feat = self.backbone.extract_features(src_img)[0]  # (H_s, W_s, D)\n",
        "        tgt_feat = self.backbone.extract_features(tgt_img)[0]  # (H_t, W_t, D)\n",
        "\n",
        "        H_s, W_s, D = src_feat.shape\n",
        "        H_t, W_t, _ = tgt_feat.shape\n",
        "\n",
        "        patch_size = self.backbone.config.patch_size\n",
        "\n",
        "        # Convert keypoint coords to patch indices\n",
        "        src_kps_patch = (src_kps / patch_size).long()\n",
        "        src_kps_patch[:, 0] = src_kps_patch[:, 0].clamp(0, W_s - 1)\n",
        "        src_kps_patch[:, 1] = src_kps_patch[:, 1].clamp(0, H_s - 1)\n",
        "\n",
        "        # Match each keypoint\n",
        "        N = src_kps.shape[0]\n",
        "        tgt_kps_pred = torch.zeros(N, 2, device=src_kps.device)\n",
        "\n",
        "        for i in range(N):\n",
        "            x, y = src_kps_patch[i]\n",
        "            src_vec = src_feat[y, x]  # (D,)\n",
        "\n",
        "            # Cosine similarity\n",
        "            similarity = F.cosine_similarity(\n",
        "                src_vec.view(1, 1, 1, D),\n",
        "                tgt_feat.unsqueeze(0),\n",
        "                dim=-1\n",
        "            ).squeeze(0)  # (H_t, W_t)\n",
        "\n",
        "            # Argmax\n",
        "            max_idx = similarity.flatten().argmax()\n",
        "            pred_y = max_idx // W_t\n",
        "            pred_x = max_idx % W_t\n",
        "\n",
        "            # Convert back to pixels\n",
        "            tgt_kps_pred[i, 0] = pred_x * patch_size + patch_size // 2\n",
        "            tgt_kps_pred[i, 1] = pred_y * patch_size + patch_size // 2\n",
        "\n",
        "        return tgt_kps_pred\n",
        "\n",
        "\n",
        "print(\" Unified matcher ready!\")"
      ],
      "metadata": {
        "id": "PlF_Vgmngt2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 6: PCK Metrics Implementation\n",
        "# ============================================================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from typing import Dict, List\n",
        "\n",
        "def compute_pck(\n",
        "    pred_kps: torch.Tensor,\n",
        "    gt_kps: torch.Tensor,\n",
        "    image_size: tuple,\n",
        "    thresholds: List[float] = [0.05, 0.10, 0.15, 0.20]\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Compute Percentage of Correct Keypoints (PCK) at multiple thresholds.\n",
        "\n",
        "    Args:\n",
        "        pred_kps: (N, 2) predicted keypoints in (x, y) format\n",
        "        gt_kps: (N, 2) ground truth keypoints in (x, y) format\n",
        "        image_size: (H, W) image dimensions\n",
        "        thresholds: List of normalized distance thresholds\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with PCK@T for each threshold\n",
        "    \"\"\"\n",
        "    H, W = image_size\n",
        "\n",
        "    # Use max dimension for normalization (standard in SPair-71k)\n",
        "    max_dim = max(H, W)\n",
        "\n",
        "    # Compute Euclidean distance\n",
        "    distances = torch.norm(pred_kps - gt_kps, dim=1)  # (N,)\n",
        "\n",
        "    # Normalize by image size\n",
        "    normalized_distances = distances / max_dim\n",
        "\n",
        "    # Compute PCK for each threshold\n",
        "    results = {}\n",
        "    for t in thresholds:\n",
        "        correct = (normalized_distances <= t).float()\n",
        "        pck = correct.mean().item()\n",
        "        results[f'PCK@{t:.2f}'] = pck\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def compute_pck_per_keypoint(\n",
        "    pred_kps: torch.Tensor,\n",
        "    gt_kps: torch.Tensor,\n",
        "    image_size: tuple,\n",
        "    thresholds: List[float] = [0.05, 0.10, 0.15, 0.20]\n",
        ") -> Dict[int, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Compute PCK per individual keypoint.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping keypoint_id -> {PCK@T metrics}\n",
        "    \"\"\"\n",
        "    H, W = image_size\n",
        "    max_dim = max(H, W)\n",
        "\n",
        "    N = pred_kps.shape[0]\n",
        "    distances = torch.norm(pred_kps - gt_kps, dim=1) / max_dim\n",
        "\n",
        "    results = {}\n",
        "    for i in range(N):\n",
        "        kp_results = {}\n",
        "        for t in thresholds:\n",
        "            correct = (distances[i] <= t).float().item()\n",
        "            kp_results[f'PCK@{t:.2f}'] = correct\n",
        "        results[i] = kp_results\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Test metrics\n",
        "print(\" Testing PCK metrics...\\n\")\n",
        "\n",
        "# Dummy data\n",
        "pred = torch.tensor([[100.0, 150.0], [200.0, 250.0], [50.0, 75.0]])\n",
        "gt = torch.tensor([[105.0, 155.0], [195.0, 245.0], [48.0, 72.0]])\n",
        "img_size = (480, 640)\n",
        "\n",
        "pck_results = compute_pck(pred, gt, img_size)\n",
        "\n",
        "print(\" PCK Results (overall):\")\n",
        "for metric, value in pck_results.items():\n",
        "    print(f\"   {metric}: {value:.4f} ({value*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n Metrics implementation working!\")"
      ],
      "metadata": {
        "id": "4f9KkzVFg6I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 7: Unified Evaluation Engine\n",
        "# ============================================================================\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "class UnifiedEvaluator:\n",
        "    \"\"\"Evaluation engine per tutti i backbones.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataloader,\n",
        "        device: str = 'cuda',\n",
        "        thresholds: list = [0.05, 0.10, 0.15, 0.20]\n",
        "    ):\n",
        "        self.dataloader = dataloader\n",
        "        self.device = device\n",
        "        self.thresholds = thresholds\n",
        "        self.results = {}\n",
        "\n",
        "    def evaluate_backbone(\n",
        "        self,\n",
        "        backbone_name: str,\n",
        "        num_samples: int = None\n",
        "    ) -> dict:\n",
        "        \"\"\"\n",
        "        Evaluate a single backbone.\n",
        "\n",
        "        Args:\n",
        "            backbone_name: Name from BACKBONE_REGISTRY\n",
        "            num_samples: Max number of samples (None = all)\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"EVALUATING: {BACKBONE_REGISTRY[backbone_name].name}\")\n",
        "        print('='*70)\n",
        "\n",
        "        # Initialize\n",
        "        backbone = UnifiedBackbone(backbone_name, device=self.device)\n",
        "        matcher = CorrespondenceMatcher(backbone)\n",
        "\n",
        "        # Storage\n",
        "        all_pck = defaultdict(list)\n",
        "        per_category = defaultdict(lambda: defaultdict(list))\n",
        "        inference_times = []\n",
        "\n",
        "        # Evaluation loop\n",
        "        n_processed = 0\n",
        "        pbar = tqdm(self.dataloader, desc=f\"{backbone_name}\")\n",
        "\n",
        "        for batch in pbar:\n",
        "            if num_samples and n_processed >= num_samples:\n",
        "                break\n",
        "\n",
        "            # Extract data\n",
        "            src_img = batch['src_img'].to(self.device)\n",
        "            tgt_img = batch['tgt_img'].to(self.device)\n",
        "            src_kps = batch['src_kps'][0]  # (N, 2)\n",
        "            tgt_kps = batch['tgt_kps'][0]\n",
        "            valid_mask = batch['valid_mask'][0]\n",
        "            category = batch['category'][0]\n",
        "\n",
        "            # Filter valid keypoints\n",
        "            src_kps_valid = src_kps[valid_mask]\n",
        "            tgt_kps_valid = tgt_kps[valid_mask]\n",
        "\n",
        "            if len(src_kps_valid) == 0:\n",
        "                continue\n",
        "\n",
        "            # Predict (with timing)\n",
        "            start = time.time()\n",
        "            tgt_kps_pred = matcher.match(src_img, tgt_img, src_kps_valid)\n",
        "            inference_times.append(time.time() - start)\n",
        "\n",
        "            # Compute metrics\n",
        "            H, W = tgt_img.shape[2:]\n",
        "            pck_scores = compute_pck(tgt_kps_pred, tgt_kps_valid, (H, W), self.thresholds)\n",
        "\n",
        "            # Store\n",
        "            for metric, value in pck_scores.items():\n",
        "                all_pck[metric].append(value)\n",
        "                per_category[category][metric].append(value)\n",
        "\n",
        "            n_processed += 1\n",
        "\n",
        "            # Update progress bar\n",
        "            if len(all_pck['PCK@0.10']) > 0:\n",
        "                avg_pck = np.mean(all_pck['PCK@0.10'])\n",
        "                pbar.set_postfix({'PCK@0.10': f'{avg_pck:.4f}'})\n",
        "\n",
        "        # Aggregate results\n",
        "        results = self._aggregate_results(\n",
        "            backbone_name, all_pck, per_category, inference_times, n_processed\n",
        "        )\n",
        "\n",
        "        self.results[backbone_name] = results\n",
        "        self._print_summary(results)\n",
        "\n",
        "        # Cleanup\n",
        "        del backbone, matcher\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _aggregate_results(self, backbone_name, all_pck, per_category, times, n_pairs):\n",
        "        \"\"\"Aggregate all metrics.\"\"\"\n",
        "\n",
        "        results = {\n",
        "            'backbone': backbone_name,\n",
        "            'display_name': BACKBONE_REGISTRY[backbone_name].name,\n",
        "            'num_pairs': n_pairs,\n",
        "            'inference_time_ms': np.mean(times) * 1000,\n",
        "            'overall': {},\n",
        "            'per_category': {}\n",
        "        }\n",
        "\n",
        "        # Overall\n",
        "        for metric in [f'PCK@{t:.2f}' for t in self.thresholds]:\n",
        "            values = all_pck[metric]\n",
        "            results['overall'][metric] = {\n",
        "                'mean': np.mean(values),\n",
        "                'std': np.std(values),\n",
        "            }\n",
        "\n",
        "        # Per-category\n",
        "        for cat, metrics in per_category.items():\n",
        "            results['per_category'][cat] = {}\n",
        "            for metric in [f'PCK@{t:.2f}' for t in self.thresholds]:\n",
        "                results['per_category'][cat][metric] = np.mean(metrics[metric])\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _print_summary(self, results):\n",
        "        \"\"\"Print evaluation summary.\"\"\"\n",
        "\n",
        "        print(f\"\\n {results['display_name']} Results:\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for metric, values in results['overall'].items():\n",
        "            print(f\"   {metric}: {values['mean']:.4f} ± {values['std']:.4f}\")\n",
        "\n",
        "        print(f\"\\n⏱  Avg inference time: {results['inference_time_ms']:.2f} ms/pair\")\n",
        "        print(f\" Evaluated on {results['num_pairs']} pairs\")\n",
        "\n",
        "    def compare_all(self) -> pd.DataFrame:\n",
        "        \"\"\"Create comparison table.\"\"\"\n",
        "\n",
        "        rows = []\n",
        "        for name, res in self.results.items():\n",
        "            row = {\n",
        "                'Backbone': res['display_name'],\n",
        "                'Pairs': res['num_pairs'],\n",
        "                'Time (ms)': f\"{res['inference_time_ms']:.1f}\",\n",
        "            }\n",
        "\n",
        "            for metric, vals in res['overall'].items():\n",
        "                row[metric] = f\"{vals['mean']:.4f}\"\n",
        "\n",
        "            rows.append(row)\n",
        "\n",
        "        df = pd.DataFrame(rows)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"FINAL COMPARISON\")\n",
        "        print(\"=\"*70)\n",
        "        print(df.to_string(index=False))\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        return df\n",
        "\n",
        "\n",
        "# Initialize evaluator\n",
        "evaluator = UnifiedEvaluator(\n",
        "    dataloader=test_loader,\n",
        "    device=device,\n",
        "    thresholds=[0.05, 0.10, 0.15, 0.20]\n",
        ")\n",
        "\n",
        "print(\"\\n Unified evaluator ready!\")"
      ],
      "metadata": {
        "id": "z74I72F_g-MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 8A: Evaluate DINOv2-ViT-B/14\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "BACKBONE_NAME = 'dinov2_vitb14'\n",
        "USE_SUBSET = True\n",
        "NUM_SAMPLES = 100 if USE_SUBSET else None\n",
        "\n",
        "print(f\"🔬 Evaluating: {BACKBONE_REGISTRY[BACKBONE_NAME].name}\")\n",
        "print(f\"   Samples: {NUM_SAMPLES if NUM_SAMPLES else 'ALL (1814)'}\")\n",
        "print(f\"   Device: {device}\\n\")\n",
        "\n",
        "# Evaluate\n",
        "try:\n",
        "    results_dinov2 = evaluator.evaluate_backbone(BACKBONE_NAME, num_samples=NUM_SAMPLES)\n",
        "\n",
        "    # Save results immediately\n",
        "    output_file = f'{RESULTS_DIR}/dinov2_vitb14_results.json'\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results_dinov2, f, indent=2)\n",
        "\n",
        "    print(f\"\\n Results saved: {output_file}\")\n",
        "\n",
        "    # Show summary\n",
        "    print(f\"\\n DINOv2 Summary:\")\n",
        "    print(f\"   PCK@0.10: {results_dinov2['overall']['PCK@0.10']['mean']:.4f}\")\n",
        "    print(f\"   Time: {results_dinov2['inference_time_ms']:.2f} ms/pair\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\n DINOv2 evaluation complete!\")"
      ],
      "metadata": {
        "id": "JWdsxbkahCHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 8B: Evaluate DINOv3-ViT-B/14 (con fallback a DINOv2)\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "\n",
        "# Configuration\n",
        "BACKBONE_NAME = 'dinov3_vitb14'\n",
        "USE_SUBSET = True\n",
        "NUM_SAMPLES = 100 if USE_SUBSET else None\n",
        "\n",
        "print(f\" Evaluating: {BACKBONE_REGISTRY[BACKBONE_NAME].name}\")\n",
        "print(f\"   Samples: {NUM_SAMPLES if NUM_SAMPLES else 'ALL (1814)'}\")\n",
        "print(f\"   Device: {device}\\n\")\n",
        "\n",
        "# Evaluate\n",
        "try:\n",
        "    results_dinov3 = evaluator.evaluate_backbone(BACKBONE_NAME, num_samples=NUM_SAMPLES)\n",
        "\n",
        "    # Save results\n",
        "    output_file = f'{RESULTS_DIR}/dinov3_vitb14_results.json'\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results_dinov3, f, indent=2)\n",
        "\n",
        "    print(f\"\\n Results saved: {output_file}\")\n",
        "\n",
        "    # Show summary\n",
        "    print(f\"\\n DINOv3 Summary:\")\n",
        "    print(f\"   PCK@0.10: {results_dinov3['overall']['PCK@0.10']['mean']:.4f}\")\n",
        "    print(f\"   Time: {results_dinov3['inference_time_ms']:.2f} ms/pair\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\n DINOv3 evaluation complete!\")"
      ],
      "metadata": {
        "id": "yFkXauvhADVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 8C: Evaluate SAM-ViT-B (OPZIONALE)\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "\n",
        "# NOTA: Richiede installazione:\n",
        "# !pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "\n",
        "# Configuration\n",
        "BACKBONE_NAME = 'sam_vit_b'\n",
        "USE_SUBSET = True\n",
        "NUM_SAMPLES = 100 if USE_SUBSET else None\n",
        "\n",
        "print(f\" Evaluating: {BACKBONE_REGISTRY[BACKBONE_NAME].name}\")\n",
        "print(f\"   Samples: {NUM_SAMPLES if NUM_SAMPLES else 'ALL (1814)'}\")\n",
        "print(f\"   Device: {device}\\n\")\n",
        "\n",
        "# Check if SAM is installed\n",
        "try:\n",
        "    import segment_anything\n",
        "    print(\" segment-anything package found\\n\")\n",
        "except ImportError:\n",
        "    print(\" SAM not installed. Installing now...\")\n",
        "    !pip install -q git+https://github.com/facebookresearch/segment-anything.git\n",
        "    print(\" Installation complete\\n\")\n",
        "\n",
        "# Evaluate\n",
        "try:\n",
        "    results_sam = evaluator.evaluate_backbone(BACKBONE_NAME, num_samples=NUM_SAMPLES)\n",
        "\n",
        "    # Save results\n",
        "    output_file = f'{RESULTS_DIR}/sam_vit_b_results.json'\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(results_sam, f, indent=2)\n",
        "\n",
        "    print(f\"\\n Results saved: {output_file}\")\n",
        "\n",
        "    # Show summary\n",
        "    print(f\"\\n SAM Summary:\")\n",
        "    print(f\"   PCK@0.10: {results_sam['overall']['PCK@0.10']['mean']:.4f}\")\n",
        "    print(f\"   Time: {results_sam['inference_time_ms']:.2f} ms/pair\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n Error: {e}\")\n",
        "    print(\" Tip: SAM might not work well for semantic correspondence\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\n SAM evaluation complete (or skipped)!\")"
      ],
      "metadata": {
        "id": "s51DfS-dAIqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELLA 9: Load All Results & Final Comparison\n",
        "# ============================================================================\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "print(\" Loading all saved results...\\n\")\n",
        "\n",
        "# Load all saved results\n",
        "all_results = {}\n",
        "\n",
        "result_files = {\n",
        "    'dinov2_vitb14': f'{RESULTS_DIR}/dinov2_vitb14_results.json',\n",
        "    'dinov3_vitb14': f'{RESULTS_DIR}/dinov3_vitb14_results.json',\n",
        "    'sam_vit_b': f'{RESULTS_DIR}/sam_vit_b_results.json',\n",
        "}\n",
        "\n",
        "for backbone_name, filepath in result_files.items():\n",
        "    if Path(filepath).exists():\n",
        "        with open(filepath, 'r') as f:\n",
        "            all_results[backbone_name] = json.load(f)\n",
        "        print(f\" Loaded: {backbone_name}\")\n",
        "    else:\n",
        "        print(f\"  Not found: {filepath}\")\n",
        "\n",
        "print(f\"\\n Loaded {len(all_results)} backbone results\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# Create Comparison Table\n",
        "# ============================================================================\n",
        "\n",
        "def create_comparison_table(results_dict):\n",
        "    \"\"\"Create comparison DataFrame.\"\"\"\n",
        "    rows = []\n",
        "\n",
        "    for name, res in results_dict.items():\n",
        "        row = {\n",
        "            'Backbone': res['display_name'],\n",
        "            'Pairs': res['num_pairs'],\n",
        "            'Time (ms)': f\"{res['inference_time_ms']:.1f}\",\n",
        "        }\n",
        "\n",
        "        for metric, vals in res['overall'].items():\n",
        "            row[metric] = f\"{vals['mean']:.4f}\"\n",
        "\n",
        "        rows.append(row)\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "comparison_df = create_comparison_table(all_results)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FINAL COMPARISON TABLE\")\n",
        "print(\"=\" * 80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save CSV\n",
        "csv_file = f'{RESULTS_DIR}/final_comparison.csv'\n",
        "comparison_df.to_csv(csv_file, index=False)\n",
        "print(f\"\\n Saved: {csv_file}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Visualizations\n",
        "# ============================================================================\n",
        "\n",
        "def plot_comparison(results_dict):\n",
        "    \"\"\"Generate comparison plots.\"\"\"\n",
        "\n",
        "    if len(results_dict) == 0:\n",
        "        print(\"  No results to plot\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    backbones = list(results_dict.keys())\n",
        "    display_names = [results_dict[b]['display_name'] for b in backbones]\n",
        "    thresholds = [0.05, 0.10, 0.15, 0.20]\n",
        "    colors = sns.color_palette('husl', len(backbones))\n",
        "\n",
        "    # Plot 1: PCK Curves\n",
        "    ax1 = axes[0]\n",
        "    for backbone, color in zip(backbones, colors):\n",
        "        res = results_dict[backbone]\n",
        "        pck_vals = [res['overall'][f'PCK@{t:.2f}']['mean'] for t in thresholds]\n",
        "        ax1.plot(thresholds, pck_vals, marker='o', linewidth=2,\n",
        "                label=res['display_name'], markersize=8, color=color)\n",
        "\n",
        "    ax1.set_xlabel('Threshold', fontsize=12, fontweight='bold')\n",
        "    ax1.set_ylabel('PCK', fontsize=12, fontweight='bold')\n",
        "    ax1.set_title('PCK Curves', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(loc='lower right')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_ylim([0, 1])\n",
        "\n",
        "    # Plot 2: PCK@0.10 Bar Chart\n",
        "    ax2 = axes[1]\n",
        "    pck_010 = [results_dict[b]['overall']['PCK@0.10']['mean'] for b in backbones]\n",
        "\n",
        "    bars = ax2.bar(range(len(backbones)), pck_010, color=colors, alpha=0.8)\n",
        "    ax2.set_xticks(range(len(backbones)))\n",
        "    ax2.set_xticklabels(display_names, rotation=45, ha='right')\n",
        "    ax2.set_ylabel('PCK@0.10', fontsize=12, fontweight='bold')\n",
        "    ax2.set_title('Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "    ax2.set_ylim([0, 1])\n",
        "    ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for bar, val in zip(bars, pck_010):\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    # Plot 3: Inference Time\n",
        "    ax3 = axes[2]\n",
        "    times = [results_dict[b]['inference_time_ms'] for b in backbones]\n",
        "    bars = ax3.bar(range(len(backbones)), times, color=colors, alpha=0.8)\n",
        "    ax3.set_xticks(range(len(backbones)))\n",
        "    ax3.set_xticklabels(display_names, rotation=45, ha='right')\n",
        "    ax3.set_ylabel('Time (ms)', fontsize=12, fontweight='bold')\n",
        "    ax3.set_title('Inference Speed', fontsize=14, fontweight='bold')\n",
        "    ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for bar, val in zip(bars, times):\n",
        "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(times)*0.02,\n",
        "                f'{val:.1f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save\n",
        "    save_path = f'{FIGURES_DIR}/final_comparison.png'\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\n Saved: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Generate plots\n",
        "plot_comparison(all_results)\n",
        "\n",
        "print(\"\\n Comparison complete!\")"
      ],
      "metadata": {
        "id": "lumBUtEjrtRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}